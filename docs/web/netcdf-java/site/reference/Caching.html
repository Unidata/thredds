<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>CDM Caching</title>
</head>

<body>
<h1><img src="../netcdfBig.gif" width="100" height="55" /> Caching</h1>
<hr />
<h2>
    Disk Caching
</h2>
<h3>
  Writing temporary files using DiskCache<a name="DiskCache" id="DiskCache"></a> 
</h3>
<p><span style="">
  <o:p>There are a number of places where the library needs to write  files to disk. If you end up using the file more than once, its useful to save these files.</o:p>
</span>Before it writes the temporary file, it  looks to see if it already exists. </p>
<ol>
  <li><span style="">
    <o:p>If a filename ends with &quot;<strong>.Z</strong>&quot;, &quot;<strong>.zip</strong>&quot;, &quot;<strong>.gzip</strong>&quot;, &quot;<strong>.gz</strong>&quot;, or &quot;<strong>.bz2</strong>&quot;, <strong>NetcdfFile.open</strong> will  write an uncompressed file of the same name, but without the suffix.</o:p>
  </span></li>
  <li>The <strong>GRIB</strong> IOSP  writes an index file with the same name with suffix <strong>.gbx8. </strong>Other IOSPs may do similar things.</li>
  <li> <strong>Nexrad2, Cinrad2 </strong> files that are compressed will be uncompressed to a file with an <strong>.uncompress</strong> prefix. </li>
</ol>
<p><span style="">
  <o:p>By default, DiskCache prefers to place the temporary file in the same directory as the original file. If it does not have write permission in that directory, by default it will use the directory <strong>${user_home}/.unidata/cache/. </strong>You can change the directory by calling </o:p>
  </span><span style="">
  <o:p><strong>ucar.nc2.util.DiskCache.setRootDirectory().</strong> </o:p>
</span></p>
<p>
You might want to always write temporary files to the cache directory, in order to manage them in a central place. To do so, call </o:p>
  <o:p>
  <strong>ucar.nc2.util.DiskCache.setCachePolicy( boolean alwaysInCache) </strong>with parameter  alwaysInCache = true<strong>. </strong><br />
  <br />
  You may want to limit the amount of space the disk cache uses (unless you always have data in writeable directories, so that the disk cache is never used). To scour the cache, call <strong>DiskCache.cleanCache</strong>(). There are several variations of the cleanup: 

<ul>
      <li><strong>DiskCache.cleanCache(Date cutoff, StringBuilder sbuff) </strong>will delete files older than the cutoff date. </li>
      <li><strong>DiskCache.cleanCache(long maxBytes, StringBuilder sbuff) </strong>will retain maxBytes bytes, deleting oldest files first.        </li>
      <li><strong>DiskCache.cleanCache(long maxBytes, Comparator&lt;File&gt; fileComparator, StringBuilder sbuff) </strong>will retain maxBytes bytes, deleting files in the order defined by your Comparator.</li>
    </ul>
    <p>For long running appplication, you might want to do this periodically in a background timer thread, as in the following example. </p>
    <o:p>    
<pre>1) Calendar c = Calendar.getInstance(); // contains current startup time
   c.add( Calendar.MINUTE, 30); // add 30 minutes to current time     // run task every 60 minutes, starting 30 minutes from now
2) java.util.Timer timer = new Timer();<strong>  
   timer.scheduleAtFixedRate</strong>( new CacheScourTask(), c.getTime(), (long) 1000 * 60 * 60 ); 

3) private class CacheScourTask extends java.util.TimerTask {   
    public void run() {
     StringBuffer sbuff = new StringBuffer();
4)<strong>   DiskCache.cleanCache</strong>(100 * 1000 * 1000, sbuff); // 100 Mbytes
     sbuff.append(&quot;----------------------\n&quot;);
5)   log.info(sbuff.toString());
    }
   }
   ...
   // upon exiting
6) <strong>timer.cancel</strong>();
</pre>
<ol>
  <li>Get the current time and add 30 minutes to it</li>
  <li>Start up a timer that executes every 60 minutes, starting in 30 minutes</li>
  <li> Your class must extend TimerTask, the run method is called by the Timer </li>
  <li>Scour the cache, allowing 100 Mbytes of space to be retained</li>
  <li>Optionally log a message with the results of the scour. </li>
  <li>Make sure you cancel the timer before your application exits, or else the process will not terminate. </li>
</ol>
<h3>GRIB indexing
</h3>
<p>In 4.0, the cache policy for GRIB indexes is set seperately from generic DiskCache, in order to give you seperate control: </p>
<pre>   <strong>GribGridServiceProvider</strong>.<strong>setIndexAlwaysInCache</strong>( true); // always use the cache for grib index</pre>
<p>Note that you still control whether to alway use a cache directory, and where that is located with DiskCache methods:</p>
<pre>   <o:p><strong> ucar.nc2.util.DiskCache.setCachePolicy( boolean alwaysInCache);<br />    ucar.nc2.util.DiskCache.setRootDirectory(String cacheDir)</strong></o:p>; 
</pre>
<p>In multi-threaded situations such as a server, you need to make sure that  grib indexing is thread-safe. One way to do this is to generate the indexes ahead of time, then tell the library to not write the index, but only use files that already have an index:</p>
<pre>   <strong>GribGridServiceProvider.setIndexExtendMode</strong>( IndexExtendMode.none); // never write an index
   <strong>GribGridServiceProvider.setIndexSyncMode</strong>( IndexExtendMode.none); // never sync the index</pre>
<p>See <a href="http://www.unidata.ucar.edu/software/decoders/">GRIB decoder</a> for details on generating a GRIB index externally. See <strong>GribGridServiceProvider</strong> <a href="http://www.unidata.ucar.edu/software/netcdf-java/v4.0/javadoc/index.html">javadoc</a> for more details.</p>
<hr width="100%" />
<h2>Object Caching</h2>
<h3>NetcdfFileCache</h3>
<p>NetcdfFile objects are cached in memory for performance. When acquired, the object is locked so another thread cannot use. When closed, the lock is removed. When the cache is full, older objects are removed from the cache, and all resources released. </p>
<p>Note that typically a <strong>java.io.RandomAccessFile</strong>   object, holding an OS file handle, is  open while its in the cache. You must make sure that your cache size is not so large such that you run out of file handles due to NetcdfFile object caching. Most aggregations do not hold more than one file handle open, no matter how many files are in the aggregation. The exception to that is a Union aggregation, which holds each of the files in the union open for the duration of the NetcdfFile object.</p>
<p>Holding a file handle open also creates a read lock on some operating systems, which will prevent the file from being opened in write mode. </p>
<p>To enable caching, you must first call</p>
<pre><strong>  NetcdfDataset.initNetcdfFileCache(int minElementsInMemory, int maxElementsInMemory, int period);</strong></pre>
<p> where <em>minElementsInMemory</em> are the number of objects to keep in the cache when cleaning up, <em>maxElementsInMemory</em> triggers a cleanup if the cache size goes over it, and <em>period</em> specifies the time in seconds to do periodic cleanups.</p>
<p>After enabling, you can disable with:</p>
<blockquote>
  <pre><strong>NetcdfDataset.disableNetcdfFileCache</strong>();</pre>
</blockquote>
<p>However, you cant reenable after disabling.</p>
<p>Setting <strong>minElementsInMemory</strong> to zero will remove all files not currently in use  every <strong>period</strong> seconds.</p>
<p>Normally the cleanup is done is a background thread to not interferre with your application, and the maximum elements is approximate. When resources such as file handles must be carefully managed,  you can set a hard limit with this call:</p>
<pre>
   <strong>NetcdfDataset.initNetcdfFileCache(int minElementsInMemory, int maxElementsInMemory, int hardLimit, int period);</strong>
</pre>
<p>  so that as soon as the number of NetcdfFile objects exceeds <em>hardLimit</em> , a cleanup is done immediately in the calling thread.</p>
<hr width="100%" />
<h2>Collection Caching Directory Scans and Metadata</h2>
<ul>
  <li>Introduced in CDM 4.2, to support large collections of  files that may change.</li>
  <li>Interface <strong>CollectionManager</strong>, has implementations <strong>DatasetCollectionManager</strong> and <strong>DatasetCollectionFromCatalog</strong></li>
  <li><strong>DatasetCollectionManager</strong> has an <strong>MController</strong> that does the directory scanning</li>
  <li>Interface<strong> MController</strong> has implementations <strong>ControllerCaching</strong> and <strong>ControllerOS</strong> (default)</li>
</ul>
<h3><strong>ControllerCaching</strong></h3>
<ul>
  <li>You must enable by calling <strong>DatasetCollectionManager</strong>.<strong>setController</strong>()
    <ul>
      <li>Done  in TDS though <strong>CdmInit</strong></li>
      <li>Done in ToolsUI by calling
        <pre> DiskCache2 cacheDir = new DiskCache2(&quot;.unidata/ehcache&quot;, true, -1, -1);<br /> ControllerCaching cacheManager = thredds.filesystem.ControllerCaching.makeTestController(cacheDir.getRootDirectory());
 thredds.inventory.DatasetCollectionManager.setController(cacheManager);</pre>
      </li>
    </ul>
  </li>
  <li>Uses ehcache object caching, so requires ehcache.jar</li>
  <li>Granularity is a directory</li>
  <li>Call the OS to get the last modified date of the directory, and if changed then make an OS request for the list of directories
    <ul>
      <li>Therefore, a good stategy is to divide data into subdirectories that minimize changes, so you dont have to scan older ones.</li>
      <li>If not changed, use the cached info<br>
        </li>
    </ul>
  </li>
</ul>
<h3>FMRC Caching</h3>
<ul>
  <li>uses Berkeley DB</li>
  <li> default root dir is ${user.home}/.unidata/bdb</li>
  <li>MetadataManager.setCacheDirectory();</li>
</ul>
<pre>&nbsp; </pre>
<hr width="100%" />
<address>
<img src="../nc.gif" width="64" height="64" /> This document is maintained by John Caron and was last updated  Oct 2010
</address>
<p>&nbsp; </p>
</body>
</html>
