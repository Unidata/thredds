<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">

  <title>TDS Tutorial: TDS Configuration Catalogs</title>
  <link rel="stylesheet" href="tutorial.css" type="text/css">
  <script language="JavaScript1.2" src="http://www.unidata.ucar.edu/acemenu/last_mod.js"></script>
  <link rel="SHORTCUT ICON" href="http://www.unidata.ucar.edu/favicon.ico" type="image/x-icon">
</head>
<body>

<h1>TDS Configuration Catalogs</h1>

<div id="section"><h2><a name="CatReview">More THREDDS Catalog Review</a></h2>

  <div id="subsection"><h3>The <code>service</code> Element</h3>

    <h4>Compound <code>service</code> Elements - Serving Datasets with Multiple Methods</h4>

    <p>Datasets can be made available through more than one access method by defining and then
      referencing a <strong>compound</strong> <code>service</code> element. The following:
    </p>

<pre>
&lt;service name="<strong>all</strong>" serviceType="Compound" base="" &gt;
    &lt;service name="odap" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="wcs" serviceType="WCS" base="/thredds/wcs/" /&gt;
&lt;/service&gt;
</pre>

    <p>defines a compound service named "all" which contains two nested services. Any dataset
      that reference the compound service will have two access methods. For instance:
    </p>

<pre>
&lt;dataset name="cool data" urlPath="so/cool/data.nc" &gt;
    &lt;serviceName&gt;<strong>all</strong>&lt;/serviceName&gt;
&lt;/dataset&gt;
</pre>

    <p>would result in these two access URLs:</p>

    <pre><code>/thredds/dodsC/so/cool/data.nc</code></pre>
    <pre><code>/thredds/wcs/so/cool/data.nc</code></pre>

    <p>Note: The contained services can still be referenced independently. For instance:</p>

    <pre>&lt;dataset name="more cool data" urlPath="more/cool/data.nc" &gt;<br>    &lt;serviceName&gt;odap&lt;/serviceName&gt;<br>&lt;/dataset&gt;</pre>

    <p>results in a single access URL:</p>

    <pre><code>/thredds/dodsC/more/cool/data.nc</code></pre>

    <h4>Unique Names Required for each <code>service</code> Element in a Catalog</h4>

    <p>Within a catalog, the service name is used to reference a <code>service</code>
      element. The service names must therefore be unique in each catalog.
      [Note: It is not necessary that they be unique globally within a TDS.
      Only on a catalog by catalog basis.]</p>
<pre>
&lt;service name="<strong>all</strong>" serviceType="Compound" base="" &gt;
    &lt;service name="<strong>odap</strong>" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="<strong>http</strong>" serviceType="HTTPServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
&lt;service name="<strong>grid</strong>" serviceType="Compound" base="" &gt;
    &lt;service name="<span style="text-decoration: line-through;"><strong>odap</strong></span>" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="wcs" serviceType="WCS" base="/thredds/wcs/" /&gt;
    &lt;service name="wms" serviceType="WMS" base="/thredds/wms/" /&gt;
    &lt;service name="<span style="text-decoration: line-through;"><strong>http</strong></span>" serviceType="HTTPServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
</pre>

    <h3>THREDDS Metadata</h3>

    <h4>Linking to Metadata</h4>
    <pre>&lt;metadata xlink:title="some good metadata" xlink:href="http://my.server/md/data1.xml" /&gt;</pre>

    <h4>Linking to Human Readable Metadata</h4>
    <pre>&lt;description xlink:title="My Data" xlink:href="http://my.server/md/data1.html" /&gt;</pre>

    <h4>Inherited Metadata</h4>
<pre>
...
    &lt;dataset name="TDS Tutorial: example inherited metadata"&gt;
        &lt;metadata inherited="true"&gt;
            &lt;serviceName&gt;odap&lt;/serviceName&gt;
            &lt;description&gt;Really great data.&lt;/description&gt;
            &lt;keyword&gt;Ocean&lt;/keyword&gt;
            &lt;keyword&gt;Temperature&lt;/keyword&gt;
            &lt;creator&gt;Ethan&lt;/creator&gt;
            &lt;publisher&gt;Ethan&lt;/publisher&gt;
            &lt;date type="created"&gt;2008-10-30T14:22&lt;/date&gt;
            <span style="font-weight: bold;">&lt;dataFormat&gt;netCDF&lt;/dateFormat&gt;</span>
        &lt;/metadata&gt;

        &lt;dataset name="TDS Tutorial: example data 1" urlPath="test/example1.nc" /&gt;
        &lt;dataset name="TDS Tutorial: example data 2" urlPath="test/example2.nc" /&gt;
        &lt;dataset name="TDS Tutorial: example data 3" urlPath="test/example3.nc" /&gt;
        &lt;dataset name="TDS Tutorial: example data 4" urlPath="test/example4.grib2"&gt;
            <span style="font-weight: bold;">&lt;dataFormat&gt;GRIB-2&lt;/dataFormat&gt;</span>
        &lt;/dataset&gt;

    &lt;/dataset&gt;
...
</pre>

    <p>Notes:</p>
    <ul>
      <li>Inherited metadata can be overwritten.</li>
    </ul>

  </div>

</div>
<div id="section"><h2><a name="ConfigCats">TDS Configuration Catalogs</a></h2>

  <div id="subsection"><h3>TDS Requirements for the <code>service</code> Elements</h3>

    <p>The TDS provides data access services at predefined URL base paths. Therefore,
      service base URLs must match the following values:</p>

    <h4>OPeNDAP</h4>
    <pre>&lt;service name="odap" serviceType="OPeNDAP" base="<strong>/thredds/dodsC/</strong>"&nbsp;/&gt;</pre>

    <h4>NetCDF Subset Service</h4>
    <pre>&lt;service name="ncss" serviceType="NetcdfSubset" base="<strong>/thredds/ncss/</strong>"&nbsp;/&gt;</pre>

    <h4>WCS</h4>
    <pre> &lt;service name="wcs" serviceType="WCS" base="<strong>/thredds/wcs/</strong>"&nbsp;/&gt;</pre>

    <h4>WMS</h4>
    <pre> &lt;service name="wms" serviceType="WMS" base="<strong>/thredds/wms/</strong>"&nbsp;/&gt;</pre>

    <h4>HTTP Bulk File Service</h4>
    <pre>&lt;service name="fileServer" serviceType="HTTPServer" base="<strong>/thredds/fileServer/"</strong>&nbsp;/&gt;</pre>

    <div id="expanded" class="troubleshooting">
      <h4>Data Requirement for Each Service</h4>
      <ul class="little">
        <li>The <strong>"HTTPServer"</strong> service can serve any file.</li>
        <li>The <strong>"OPeNDAP"</strong> service can serve any data file that the
          netCDF-Java library can open.
        </li>
        <li>The <strong>"WCS"</strong> service can only serve data files that the
          netCDF-Java library can recognize as "gridded" data.
        </li>
        <li>The <strong>"WMS"</strong> service also only serves "gridded" data files.</li>
        <li>The <strong>"NetcdfSubset"</strong> service also only serves "gridded" data
          files.
        </li>
      </ul>
      <p>You can check that a data file is recognized as "gridded" with netCDF-Java ToolsUI.
        (ToolsUI can be found on the
        <a href="http://www.unidata.ucar.edu/software/netcdf-java/">netCDF-Java home page</a>.)</p>
    </div>

  </div>
  <div id="subsection"><h3>TDS Configuration Catalogs and Metadata</h3>

    <p>The datasetScan element is an extension of the dataset element and so can contain metadata.</p>

<pre>
...
      &lt;service name="odap" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;

<strong>2)</strong>    &lt;datasetScan name="Test all files in a directory" ID="testDatasetScan"
                   path="<strong>my/test/all</strong>" location="/my/data/testdata"&gt;
          &lt;metadata inherited="true"&gt;
              &lt;serviceName&gt;odap&lt;/serviceName&gt;
              &lt;keyword&gt;Ocean&lt;/keyword&gt;
              &lt;keyword&gt;Temperature&lt;/keyword&gt;
              &lt;creator&gt;Ethan&lt;/creator&gt;
              &lt;publisher&gt;Ethan&lt;/publisher&gt;
              &lt;date type="created"&gt;2008-10-30T14:22&lt;/date&gt;
          &lt;/metadata&gt;
      &lt;/datasetScan&gt;
...
</pre>

    <p>All generated catalogs that are descendants of this datasetScan will contain
      all inherit metadata contained in the datasetScan element. For instance, here
      is a resulting child catalog:</p>

<pre>
...
      &lt;service name="odap" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;

      &lt;dataset name="Test all files in a directory" ID="testDatasetScan" &gt;
          &lt;metadata inherited="true"&gt;
              &lt;serviceName&gt;odap&lt;/serviceName&gt;
              &lt;keyword&gt;Ocean&lt;/keyword&gt;
              &lt;keyword&gt;Temperature&lt;/keyword&gt;
              &lt;creator&gt;Ethan&lt;/creator&gt;
              &lt;publisher&gt;Ethan&lt;/publisher&gt;
              &lt;date type="created"&gt;2008-10-30T14:22&lt;/date&gt;
          &lt;/metadata&gt;
          &lt;dataset name="afile.nc" ID="testDatasetScan/afile.nc" urlPath="<strong>my/test/all</strong>/afile.nc"&gt;
          &lt;dataset name="testData.nc" ID="testDatasetScan/afile.nc" urlPath="<strong>my/test/all</strong>/testData.nc"&gt;
          &lt;dataset name="junk.nc" ID="testDatasetScan/afile.nc" urlPath="<strong>my/test/all</strong>/junk.nc"&gt;

          &lt;catalogRef xlink:title="grib" ID="testDatasetScan/grib" name=""
                      xlink:href="/thredds/catalog/<code>my/test/all</code>/grib/catalog.xml" /&gt;
      &lt;/dataset&gt;
...
</pre>


  </div>
  <div id="subsection"><h3>TDS Root Catalog</h3>

    <p>At startup, the TDS reads the root catalog</p>

    <pre>${TOMCAT_HOME}/content/thredds/catalog.xml</pre>
    <p>and recursively all configuration catalogs that are linked to it through a relative
      <code>catalogRef</code> element . The resulting tree of catalogs are used as the
      top-level catalogs served by the TDS. In the case of our distributed root catalog,
      the tree looks like:</p>
    <pre>catalog.xml<br>    |<br>    |-- enhancedCatalog.xml<br></pre>
    <p>The tree of configuration catalogs can be as deeply nested as desired.</p>

    <h4>Additional Root Catalogs</h4>

    <p>Additional root configuration catalogs can be defined in </p>
    <pre>${TOMCAT_HOME}/content/thredds/<strong>threddsConfig.xml</strong> </pre>
    <p>file. For instance, to add a test catalog add the following line:</p>
    <pre>&lt;catalogRoot&gt;myTestCatalog.xml&lt;/catalogRoot&gt;<br></pre>
    <p>Each additional root configuration catalog can be the root of another tree of configuration catalogs.</p>

    <h4>Tools to Manage Configuration Catalogs </h4>

    <p>First, the TDS catalog errors log</p>
    <pre>${TOMCAT_HOME}/content/thredds/logs/catalogErrors.log </pre>

    <p>contains all warning and error messages from parsing the
      configuration catalogs. As such, it is a great place to look for
      information if you run into problems with your TDS configuration
      catalogs </p>

    <p>Second, the TDS Remote Management page provides access
      to a list of all the configuration catalogs the TDS has successfully
      read:</p>
    <ul>
      <li>From the TDS Remote Management page - <a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>
        <br><br>
        <img alt="TDS Remote Management page (top)" src="../images/TdsRemoteManager_top.png">
        <br>
      </li>
      <li>Click on the "Show static catalogs" link - <a href="https://localhost:8443/thredds/admin/debug?catalogs/showStatic">
        https://localhost:8443/thredds/admin/debug?catalogs/showStatic</a>:
        <br><br>
        <img alt="List of Static Catalogs" src="../images/TdsRemoteManager_staticCatalogs.png">
        
        <br>
      </li>
    </ul>
  </div>

  <div id="subsection"><h3>Managing <code>datasetRoot</code> and <code>datasetScan</code> Elements</h3>

    <p>You can have as many datasetRoot and datasetScan elements as you want, for example </p>

<pre>
&lt;datasetRoot path="<strong>model</strong>" location="<strong>/data/ncep</strong>" /&gt;
&lt;datasetRoot path="<strong>obs</strong>" location="<strong>/data/raw/metars</strong>" /&gt;
&lt;datasetRoot path="<strong>cases/001</strong>" location="<strong>C:/casestudy/data/001</strong>" /&gt;
&lt;datasetScan path="<strong>myData</strong>" location="<strong>/data/ncep/run0023</strong>" name="NCEP/RUN 23" serviceName="myserver" /&gt;
&lt;datasetScan path="<strong>myData/gfs</strong>" location="<strong>/pub/ldm/gfs</strong>" name="NCEP/GFS" serviceName="myserver" /&gt;
</pre>
    
    <p>The datasetRoot and datasetScan are said to define a
      <strong>data root</strong>.</p>
    
    <div id="expanded" class="troubleshooting">

      <h4>The Rules for Data Roots</h4>
      <ul>
        <li>Each accessible dataset must be associated with a data root, i.e.
          the beginning part of its path must match a data root path. If there
          are multiple matches, the longest match is used.
        </li>
        <li><strong>Each data root must have a unique <code>path</code> for
          all catalogs used by the TDS.</strong>
          <p>
            Note: Because the TDS uses the set of all given path values
            to map URLs to datasets, each path value MUST be unique across all
            config catalogs on a given TDS installation. Duplicates will cause
            warning messages in the <code>catalogErrors.log</code> file.
          </p>
        </li>
        <li>The directory pointed to by <strong>location</strong> should be absolute</li>
        <li>The locations may be used in multiple data roots</li>
      </ul>
    </div>

    <p>For example, using the above data roots, the following matches would be made:</p>

    <table style="width: 611px; height: 150px;" border="1">
      <tbody>
      <tr>
        <th scope="col" width="238">urlPath</th>
        <th scope="col" width="357">file</th>
      </tr>
      <tr>
        <td><code><strong>model</strong>/run0023/mydata.nc</code></td>
        <td><code><strong>/data/ncep</strong>/run0023/mydata.nc</code></td>
      </tr>
      <tr>
        <td><code><strong>obs</strong>/test.nc</code></td>
        <td><code><strong>/data/raw/metars</strong>/test.nc</code></td>
      </tr>
      <tr>
        <td><code><strong>myData</strong>/mydata.nc</code></td>
        <td><code><strong>/data/ncep/run0023</strong>/mydata.nc</code></td>
      </tr>
      <tr>
        <td><code><strong>myData/gfs</strong>/mydata.nc</code></td>
        <td><code><strong>/pub/ldm/gfs</strong>/mydata.nc</code></td>
      </tr>
      <tr>
        <td><code><strong>cases/001</strong>/test/area/two</code></td>
        <td><code><strong>C:/casestudy/data/001</strong>/test/area/two</code></td>
      </tr>
      </tbody>
    </table>

    <p>The structure of a full OPeNDAP URL for the first urlPath above would
      look like:</p>

<pre>
http://hostname:port/thredds/dodsC/model/run0023/mydata.nc
|&lt;---  server   ---&gt;|&lt;-----&gt;|&lt;---&gt;|&lt;---&gt;|&lt;-   filename  -&gt;|
                        |      |     |
           webapp name -|      |     |- data root
                               |
                      service -|
</pre>

    <h4>TDS Remote Management - List of Dataset Roots</h4>

    <p>The TDS Remote Management page has a link to list all known dataset roots:</p>
    <ul>
      <li>From the TDS Remote Management page - <a href="http://localhost:8080/thredds/debug">http://localhost:8080/thredds/debug</a>
      </li>
      <li>Click on the "Show data roots" link - <a href="https://localhost:8443/thredds/debug?catalogs/showRoots">https://localhost:8443/thredds/debug?catalogs/showRoots</a>:
        <br><br>

        <div style="margin-left: 40px;"><img style="width: 635px; height: 359px;"
                                             alt="TDS Remote Management - List of Data Roots"
                                             src="../images/TdsRemoteManager_dataRoots.png"></div>
      </li>
    </ul>

  </div>


  <div id="subsection" class="exercise"><h3>Exercise: Managing multiple roots</h3>
    <ol>
      <li>Add a few more datasetScan elements (/data/ldm/fsl, /data/ldm/madis, /data/ldm/suomi):
        <pre><strong>[thredds@workshop00 ~]$</strong> ls /data/ldm<br>bufr    dusk         dusk.080527  fsl     ldm.pq  ltng   mcidas    ngrid  nogaps    rcm      severe  surface   wseta<br>cosmic  dusk.080522  forecasts    gempak  logs    madis  nam_12km  nldn   rawfiles  rtmodel  suomi   upperair</pre>
        <pre><strong>[thredds@workshop00 ~]$</strong> ls /data/ldm/fsl<br>01hr  06min  RASS<br><strong>[thredds@workshop00 ~]$</strong> ls /data/ldm/fsl/01hr<br>20082962000.nc  20082981400.nc  20083000800.nc  20083020200.nc  20083032000.nc  20083051400.nc  20083071000.nc  20083090400.nc<br>...<br>20082981200.nc  20083000600.nc  20083020000.nc  20083031800.nc  20083051200.nc  20083070800.nc  20083090200.nc  20083102100.nc</pre>
        <pre><strong>[thredds@workshop00 ~]$</strong> ls /data/ldm/madis<br>20081022_0700.nc  20081024_1000.nc  20081026_1300.nc  20081028_1600.nc  20081030_1900.nc  20081101_2200.nc  20081104_0100.nc<br>...<br>20081024_0300.nc  20081026_0600.nc  20081028_0900.nc  20081030_1200.nc  20081101_1500.nc  20081103_1800.nc  20081105_2100.nc</pre>
        <pre><strong>[thredds@workshop00 ~]$</strong> ls /data/ldm/suomi<br>CsuPWVh_2008.308.18.00.0060_nc  CsuPWVh_2008.309.07.00.0060_nc  CsuPWVh_2008.309.20.00.0060_nc  CsuPWVh_2008.310.09.00.0060_nc<br>...<br>CsuPWVh_2008.309.04.00.0060_nc  CsuPWVh_2008.309.17.00.0060_nc  CsuPWVh_2008.310.06.00.0060_nc  CsuPWVh_2008.310.19.00.0060_nc</pre>
      </li>
      <li>Edit the main TDS configuration catalog:
<pre>
<strong>[thredds@workshop00 ~]$</strong> cd ${TOMCAT_HOME}/content/thredds
<strong>[thredds@workshop00 ~]$</strong> vi catalog.xml     <var>// Use the editor of your choice</var>
</pre>
      </li>
      <li>And add a <code>datasetScan</code> element for the FSL data:
<pre>
&lt;datasetScan name="<strong>FSL</strong>" ID="<strong>FSL</strong>"
             path="<strong>fsl</strong>" location="<strong>/data/ldm/fsl</strong>"&gt;

    &lt;metadata inherited="true"&gt;
        &lt;serviceName&gt;thisDODS&lt;/serviceName&gt;
    &lt;/metadata&gt;<br>
&lt;/datasetScan&gt;
</pre>
      </li>
      <li>And similarly for MADIS and Suomi data</li>
      <li><strong>Reinitialize the TDS configuration catalogs</strong>:
        <ol>
          <li>
            Go to the TDS Remote Management page:
            <code>
              <a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>
            </code>
          </li>
          <li>Click on the "Reinitialize" link</li>  
        </ol>
      </li>
      <li>Test that the new <code>datasetScan</code> elements are working:
        <ol>
          <li>Bring the catalog up in a browser:
            <code><a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a></code>
          </li>
          <li>Browse into the new dataset collections.
          </li>
          <li>Try an OPeNDAP access method link</li>
        </ol>
      </li>
    </ol>
    <h4>Now that we have multiple dataset roots ...</h4>
    <ol>
      <li>Lets check the list of dataset roots:</li>
      <ol>
        <li>
          Go back to the TDS Remote Management page:
          <code>
            <a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>
          </code>
        </li>
        <li>Select the "Show data roots" link.</li>
      </ol>
      <li>Check the catalogInit.log:
        <ol>
          <li>TDS Remote Management page
            [<a href="http://localhost:8080/thredds/debug">http://localhost:8080/thredds/debug</a>]
          </li>
          <li>Click the "Show TDS Logs" link.</li>
          <li>Select the "catalogInit.log" file</li>
        </ol>
      </li>
    </ol>

  </div>

  <div id="subsection" class="exercise"><h3>Exercise: Duplicate Roots</h3>

    <ol>
      <li>
        Modify the FSL <code>datasetScan</code> element so that the value of the
        path attribute matches the one for the NAM_12km <code>datasetScan</code>
        element.
<pre>
<strong>[thredds@workshop00 ~]$</strong> cd ${TOMCAT_HOME}/content/thredds
<strong>[thredds@workshop00 ~]$</strong> vi catalog.xml     <var>// Use the editor of your choice</var>
</pre>
      </li>
      <li>Reinitialize the TDS
        [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>].
      </li>
      <li>What happens with duplicate data roots:
        <ol>
          <li>
            Browse into the FSL dataset
            [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
          </li>
          <li>Check the list of dataset roots
            [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>]
          </li>
          <li>Check the catalogInit.log
            [<a href="http://localhost:8080/thredds/debug">http://localhost:8080/thredds/debug</a>]
          </li>
        </ol>
      </li>
      <li>Now fix the FSL datasetScan element.</li>
    </ol>

  </div>
</div>
<div id="section"><h2><a name="DatasetScan">More <code>datasetScan</code> Element</a></h2>

  <div id="subsection"><h3>Including Only the Desired Files</h3>

    <p>A <code>datasetScan</code> element can specify
      which files and directories it will include with a <code>filter</code>
      element (see <a href="../catalog/v1.0.2/InvCatalogSpec.server.html#filter_Element">spec</a>
      for more details). When no <code>filter</code> element is
      given, all files and
      directories are included in the generated catalog(s). Adding a <code>filter</code>
      element to your <code>datasetScan</code> element allows
      you to include (and/or exclude)
      the files and directories as desired. The <code>datasetScan</code> element for the NAM_12km example included
      the
      following:<br>
    </p>
    <pre>&lt;filter&gt;<br>    &lt;include wildcard="*.grib2" /&gt;<br>&lt;/filter&gt;<br></pre>
    <p>To exclude the analysis data, the filter could be modified to:</p>
    <pre>&lt;filter&gt;<br>    &lt;include wildcard="*.grib2" /&gt;<br>    &lt;exclude wildcard="*f000.grib2" /&gt;<br>&lt;/filter&gt;</pre>
    <p>The <code>include</code> and <code>exclude</code>
      elements both determine which datasets they match on whether their
      wildcard pattern (given by the <code>wildcard</code>
      attribute) or <a href="http://www.regular-expressions.info/">regular
        expression</a> (given by the <code>regExp</code>
      attribute) match the dataset name. By default, includes and excludes
      apply only to
      regular files (atomic datasets). You can specify that they apply to
      directories (collection datasets) as well by using the <code>atomic</code>
      and <code>collection</code>
      attributes. For example, if the nam_12km directory contained a badData
      directory, I could exclude it by adding the following to the filter:<br>
    </p>
    <pre>&lt;exclude wildcard="badData" atomic="false" collection="true" /&gt;</pre>
  </div>
  <div id="subsection" class="exercise"><h3>Exercise: Filtering Files</h3>

    <ol>
      <li>Browse one of the datasets you just added and find a
        "<strong>.scour*</strong>" file. Try the OPeNDAP access method:
<pre>
Error {
    code = 500;
    message = "Cant read /data/ldm/madis/.scour*: not a valid NetCDF file.";
};
</pre>
      </li>
      <li>Now add a <code>filter</code> element to the <code>datasetScan</code>
        elements. Something like:
<pre>
&lt;filter&gt;
    &lt;include wildcard="<strong>*.nc</strong>" /&gt;
    &lt;include wildcard="<strong>*.grib1</strong>" /&gt;
    &lt;include wildcard="<strong>*.grib2</strong>" /&gt;
&lt;/filter&gt;
</pre>
      </li>
      <li>Reinitialize the TDS
        [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>].
      </li>
      <li>
        Are the filters working?
        [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
      </li>
    </ol>
  </div>
  <div id="subsection" class="exercise"><h3>Exercise: Filtering Directories</h3>

    <ol>
      <li>Browse around in the "FSL" dataset.</li>
      <li>Add a <code>filter</code> element to the "FSL" <code>datasetScan</code>
        element to exclude the "06min" directories. Something like:
<pre>
&lt;exclude wildcard="<strong>06min</strong>" atomic="false" collection="true" /&gt;
</pre>
      </li>
      <li>Reinitialize the TDS
        [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>].
      </li>
      <li>
        Are the filters working?
        [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
      </li>
    </ol>
  </div>
  <div id="subsection"><h3>Generating IDs</h3>

    <p>All generated datasets are given an ID. The IDs are simply the
      path
      of the dataset appended to the datasetScan path value or, if one
      exists, the ID of the datasetScan element. So, for the <code>nam_12km</code>
      directory and our current configuration:<br>
    </p>
    <pre>&lt;datasetScan name="NCEP NAM 12km" ID="<strong>NAM_12km</strong>" <br>             path="nam_12km" location="/data/ldm/nam_12km"&gt;</pre>
    <p>and the data file 2008110406f018.grib2, the value of the dataset ID would be
      "NAM_12km/2008110406f018.grib2". </p>

  </div>
  <div id="subsection"><h3><a name="Naming_Datasets"></a>Naming Datasets</h3>

    <p>
      By default, all datasets are named with the corresponding
      file
      name. By adding a namer element, you can specify more human readable
      dataset names. The following namer looks for the dataset named
      "NAM_12km" and renames it with the replace string:</p>
    <pre>&lt;namer&gt;<br>    &lt;regExpOnName regExp="NCEP NAM 12km" replaceString="NCEP NAM 12km model data" /&gt;<br>&lt;/namer&gt;</pre>
    <p>More complex renaming is possible as well. The namer uses a <a href="http://www.regular-expressions.info/">regular
      expression</a> match on the dataset name. If the match succeeds,
      any regular expression <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg">capturing
        groups</a> are used in the replacement string.<br>
    </p>

    <p>A capturing group is a part of a regular expression enclosed
      in
      parenthesis. When a regular expression with a capturing group is
      applied to a string, the substring that matches the capturing group is
      saved for later use. The captured strings can then be substituted into
      another string in place of capturing group references,"$n", where "n"
      is an integer indicating a particular capturing group. (The capturing
      groups are numbered according to the order in which they appear in the
      match string.) For example, the regular expression "Hi (.*), how are
      (.*)?" when applied to the
      string "Hi Fred, how are you?" would capture the strings "Fred" and
      "you". Following that with a capturing group replacement in the string
      "$2 are $1." would result in the string "you are Fred."</p>

    <p>Here's an example namer:</p>
    <pre>&lt;namer&gt;<br>    &lt;regExpOnName regExp="([0-9]{4})([0-9]{2})([0-9]{2})([0-9]{2})f([0-9]{3}).grib2"<br>                  replaceString="NCEP NAM 12km $1-$2-$3 $4 GMT - Forecast hour: $5"/&gt;<br>&lt;/namer&gt;<br></pre>
    <p>the regular expression has five capturing groups</p>
    <ol>
      <li>The first capturing group, "([0-9]{4})", captures
        four digits, in this case the year.<br>
      </li>
      <li>The second capturing group, "([0-9]{2})", captures two
        digits, in this case the month.<br>
      </li>
      <li>The third capturing group, "([0-9]{2})", captures two
        digits, in this case the day of the month.<br>
      </li>
      <li>The fourth capturing group, "([0-9]{2})", captures two
        digits, in this case the hour of the day.
      </li>
      <li>The fifth capturing group, "([0-9]{3})", captures three
        digits, in this case the forecast hour.
      </li>
    </ol>
    <p>
      When applied to the dataset name
      "2008110406f018.grib2", the
      strings
      "2008", "11", "04", "06", and "018" are captured. After replacing the
      capturing group references in the <code>replaceString</code>
      attribute value, we get
      the name "NCEP NAM 12km 2008-11-04 06 GMT - Forecast hour: 018".<br>
    </p>

  </div>
  <div id="subsection" class="exercise"><h3>Exercise: Naming the Suomi Datasets</h3>

    <ol>
      <li>
        Add a <code>namer</code> element to the Suomi <code>datasetScan</code>
        element that extracts the date/time from the file name and uses the
        date/time in generating a new name (similar to above)
        
        the value of the
        path attribute matches the one for the NAM_12km <code>datasetScan</code>
        element.
      </li>
    </ol>

  </div>
  
  <div id="subsection"><h3>Sorting Datasets</h3>

    <div id="note" class="info"><h4>Sorting: Underlying Implementation Details</h4>
      <ol class="little">
        <li>The "natural" order of the datasets is determined by the
          order returned by the listDatasets() method in CrawlableDataset.
        </li>
        <li>The sort is done on the CrawlableDataset list. The naming
          discussed in
          the previous section is done to the resulting InvDataset. Therefore,
          the naming discussed above does not affect the sort order.
        </li>
      </ol>
    </div>

    <p>A <code>sort</code> element can be added to a <code>datasetScan</code>
      to specify the order in which a collection of datasets are listed.
      Without a <code>sort</code> element, datasets at each
      collection level are listed
      in their "natural" order. Currently, the only supported sort algorithm
      sorts datasets lexigraphically by name either in increasing
      or
      decreasing order. Here's what a <code>sort</code> element
      looks like:</p>
    <pre>&lt;sort&gt;<br>    &lt;lexigraphicByName increasing="false" /&gt;<br>&lt;/sort&gt;</pre>

  </div>
  <div id="subsection"><h3>Adding a "Latest" Proxy Datasets</h3>

    <p>With a real-time archive, it is convenient to define a "proxy" dataset
      that always points to the most recent dataset in a collection. Other
      types of proxy datasets may be useful as well and the <code>addProxies</code>
      element provides a place for
      describing proxy datasets. Currently,
      only two <code>addProxies</code> child elements are
      defined. They are both "Latest" proxy elements.
      The <code>simpleLatest</code> element adds a proxy dataset
      which proxies the existing dataset whose name is lexigraphically
      greatest (which finds the latest dataset assuming a timestamp is part
      of the dataset name). The <code>latestComplete</code>
      element behaves similarly to <code>simpleLatest</code>
      except that the proxied dataset does not include any datasets that have
      been modified more recently than a given time limit, e.g., you could
      specify
      you want the most recent (lexigraphically) dataset that hasn't been
      modified for 60 minutes. Both the <code>simpleLatest</code>
      and <code>latestComplete</code>
      elements must point to an existing <code>service</code>
      element.

    <p>

    <p>To add a "Latest" dataset to our "NAM_12km" dataset, we
      could add:</p>

    <pre>&lt;service name="latest" type="Resolver" base="" /&gt;<br></pre>

    <p>to our catalog and</p>

    <pre>&lt;addProxies&gt;<br>    &lt;latestComplete name="latestComplete.xml" top="true" serviceName="latest" lastModifiedLimit="60" /&gt;<br>&lt;/addProxies&gt;<br></pre>

    <p>to our "NAM_12km" <code>datasetScan</code>
      element. This would result in the following dataset being at the top of
      the "NAM_12km" collection of datasets:
    </p>

    <pre>&lt;dataset name="latestComplete.xml" serviceName="latest" urlPath="latestComplete.xml" /&gt;</pre>

    <p>The <code>latestComplete</code> element includes
      a <code>name</code> attribute which provides the name of
      the proxy dataset, the <code>serviceName</code> attribute
      that references the service used by the proxy dataset, the <code>top</code>
      attribute which indicates if the proxy dataset should appear at the top
      or bottom of the list of datasets in this collection, and the <code>lastModifiedLimit</code>
      which feeds into the algorithm which determines which dataset is being
      proxied.<br>
    </p>

    <p>The <code>simpleLatest</code> element allows for
      the same attributes as the <code>latestComplete</code>
      element minus the <code>lastModifiedLimit</code>
      attribute. In this case, all the attributes have default values: the <code>name</code>
      attribute defaults to "latest.xml", the <code>top</code>
      attribute defaults to "true", and the <code>serviceName</code>
      attribute defaults to "latest".<br>
    </p>

  </div>
  <div id="subsection"><h3>Adding Dataset Size Information</h3>

    <p>The <code>addDatasetSize</code> element indicates
      that file size metadata should be added to all atomic datasets. Adding<br>
    </p>

    <pre>&lt;addDatasetSize /&gt;<br></pre>

    <p>to a <code>datasetScan</code> element results in
      the addition of a <code>dataSize</code> element to each
      atomic dataset:</p>

    <pre>&lt;dataSize units="Kbytes"&gt;6.08&lt;/dataSize&gt;<br></pre>

  </div>
  <div id="subsection"><h3>Adding <code>timeCoverage</code> Elements</h3>

    <p>
      A datasetScan element may contain an <code>addTimeCoverage</code>
      element. The
      <code>addTimeCoverage</code> element indicates that a <code>timeCoverage</code>
      metadata element
      should be added to each dataset in the collection and describes
      how to determine the time coverage for each datasets in the collection.</p>

    <p>Currently, the <code>addTimeCoverage</code>
      element can only construct
      start/duration <code>timeCoverage</code> elements and uses
      the dataset name to determine the start time. As described in the <a href="#Naming_Datasets">"Naming
        Datasets" section</a> above, the addTimeCoverage element applies
      a <a href="http://www.regular-expressions.info/">regular
        expression</a> match to the dataset name. If the match succeeds,
      any regular expression <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg">capturing
        groups</a> are used in the start time replacement string to build
      the start time string. The values of the following attributes are used to
      determine the time coverage: </p>
    <ol>
      <li>Either the <code>datasetNameMatchPattern</code> or the
        <code>datasetPathMatchPattern</code> attribute gives a regular expression
        used to match on the dataset name or path, respectively. If a match is
        found, a <strong>timeCoverage</strong> element is added to the dataset.
        The match pattern should include <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg"
                >capturing groups</a> which allow the match to save substrings from the
        dataset name.
      </li>
      <li>The <code>startTimeSubstitutionPattern</code>
        attribute value has all capture group references ("$n") replaced by the
        corresponding substring that was captured during the match. The
        resulting string is used as the start value of the resulting <code>timeCoverage</code>
        element.
      </li>
      <li>The <code>duration</code> attribute value is
        used as the duration value of the resulting <code>timeCoverage</code>
        element.<br>
      </li>
    </ol>
    <p>For instance, adding</p>

<pre>
&lt;addTimeCoverage datasetNameMatchPattern="([0-9]{4})([0-9]{2})([0-9]{2})([0-9]{2})f[0-9]{3}.grib2"
                 startTimeSubstitutionPattern="$1-$2-$3T$4:00:00"
                 duration="60 hours" /&gt;
</pre>

    <p>to a <code>datasetScan</code> element and given a data file named</p>

<pre>2005071812f006.grib2</pre>

    <p>results in the following <code>timeCoverage</code> element:</p>

<pre>
&lt;timeCoverage&gt;
    &lt;start&gt;2005-07-18T12:00:00&lt;/start&gt;
    &lt;duration&gt;60 hours&lt;/duration&gt;
&lt;/timeCoverage&gt;
</pre>

  </div>
  <div id="subsection" class="exercise"><h3>Exercise: Add timeCoverage to the Suomi Datasets</h3>

    <ol>
      <li>
        Add an <code>addTimeCoverage</code> element to the Suomi <code>datasetScan</code>
        element that extracts the date/time from the file name and uses the
        date/time to generate the <code>timeCoverage</code> element (similar to above).
      </li>
    </ol>

  </div>

</div>

<p>
  <img src="../images/thread.png" height="60" alt="THREDDS" valign="top" align="left" vspace="0" hspace="10"/>
  This document is maintained by Unidata and was last updated
  <script language="JavaScript" type="text/JavaScript">
    document.write(date_modified);
  </script>
  Send comments to <a href="mailto:support-thredds@unidata.ucar.edu">THREDDS support</a>.
</p>

</body>
</html>