<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>GRIB Feature Collections</title>
<style type="text/css">
pre {font-size: 9pt; padding: 10px; background-color: #E7E7E7; border: 1px solid #CFCFCF; width: 85%;}
code {font-size: 11pt;}
dl {margin: 10px 5px 5px 15px;}
</style>
</head>

<body>
<h1>GRIB Collections</h1>
<p>Status: beta code in TDS 4.3</p>
<p>See <a href="FeatureCollections.html">Feature Collection</a> overview.</p>
<hr />
<h3>Example:</h3>
<pre>1) &lt;featureCollection name=&quot;GFS-Puerto_Rico_191km&quot; featureType=&quot;GRIB&quot; harvest=&quot;true&quot; path=&quot;fmrc/NCEP/GFS/Puerto_Rico_191km&quot;&gt;
2)   &lt;metadata inherited=&quot;true&quot;&gt;
3)     &lt;dataFormat&gt;GRIB-1&lt;/dataFormat&gt;
       &lt;documentation type=&quot;summary&quot;&gt;NCEP GFS Model : AWIPS 205 (L) Grid. National - Puerto Rico (polar stereographic).
         Model runs are made at 0Z, with analysis and forecasts every 12 hours out 10 days.
       &lt;/documentation&gt;
     &lt;/metadata&gt;
4)   &lt;collection spec=&quot;/data/ldm/pub/native/grid/NCEP/GFS/Puerto_Rico_191km/.*grib1$&quot;&gt;
5)   &lt;update startup=&quot;true&quot; rescan=&quot;0 0/15 * * * ? *&quot; trigger=&quot;allow&quot;/&gt;
6)   &lt;gribConfig datasetTypes=&quot;collection Files&quot; /&gt;
   &lt;/featureCollection&gt;</pre>
<ol>
  <li>A featureCollection must have a <em>name</em> and a <em>path</em>, recommend that you not specify an <em>ID</em>, which will then default to the  <em>path</em>. The <em>featureType</em> attribute is set to <em>GRIB</em>. </li>
  <li>A featureCollection is a InvDataset, so it can contain any elements an InvDataset can contain. It must have or inherit a default service.</li>
  <li>The collection must consist of GRIB-1 or GRIB-2 files. You must set the dataFormat to indicate which.</li>
  <li>The <a href="CollectionSpecification.html">collection specification</a>. If you dont put a <em>name</em> attribute, the featureCollection name is used. This name must be unique for all collections on this TDS server.</li>
  <li>The collection changes, so the <em>update</em> element says to rescan it on TDS startup and every 15 minutes. </li>
  <li>See below.</li>
</ol>
<hr />
<h3>gribConfig element</h3>
<p>The schema definition:</p>
<pre>  &lt;xsd:complexType name=&quot;gribConfigType&quot;&gt;<br />    &lt;xsd:sequence&gt;<br />      &lt;xsd:element name=&quot;gdsHash&quot;&gt;<br />        &lt;xsd:complexType&gt;<br />          &lt;xsd:attribute name=&quot;from&quot; type=&quot;xsd:int&quot;/&gt;<br />          &lt;xsd:attribute name=&quot;to&quot; type=&quot;xsd:int&quot;/&gt;<br />          &lt;xsd:attribute name=&quot;groupName&quot; type=&quot;xsd:string&quot;/&gt;<br />			&lt;/xsd:complexType&gt;<br />      &lt;/xsd:element&gt;<br />    &lt;/xsd:sequence&gt;<br />    &lt;xsd:attribute name=&quot;datasetTypes&quot; type=&quot;xsd:string&quot;/&gt;<br />  &lt;/xsd:complexType&gt;</pre>
<p>Defines options on feature collections with <strong> featureType</strong>=&quot;GRIB&quot;. Example:</p>
<pre>1) &lt;gribConfig datasetTypes=&quot;Collection Files&quot; &gt;
2)   &lt;gdsHash from=&quot;-2121584860&quot; to=&quot;28944332&quot;/&gt;<br />3)   &lt;gdsHash to=&quot;28944332&quot; groupName=&quot;KTAL&quot;/&gt;<br />4)   &lt;intervalMerge/&gt;<br />   &lt;/gribConfig&gt;</pre>
<ol>
  <li><strong>datasetTypes</strong>: define which 
  datasets are available in the TDS catalog
  <ol>
    <li>
      <strong>Collection</strong>: the collection level dataset</li>
    <li><strong>Files</strong>:
      each physical file
    is exposed as a seperate dataset.</li>
    </ol>
  </li>
  <li><strong>gdsHash</strong>: translate any gds hash that equals &quot;-2121584860&quot; to &quot;28944332&quot;. This is used to fix minor errors in the GDS encoding.</li>
  <li><strong>groupName</strong>: use the name &quot;KTAL&quot; for the group with gdsHash &quot;28944332&quot;.</li>
  <li><strong>intervalMerge</strong>: normally, time coordinates with seperate intervals are kept seperate.</li>
</ol>
<hr />
<h2>Implementation Notes</h2>
<h3>Index</h3>
<p>Example 1. GFS global half degree - 45 day archive</p>
<pre>
 Rectilyser: nvars=117 records unique=132684 total=3637805 dups=3505121 (0.963526)
 createIndex for /data/ldm/pub/native/grid/NCEP/GFS/Global_0p5deg/NCEP-GFS-Global_0p5deg.ncx
 write RecordMaps: bytes = 1265209 record = 132684 bytesPerRecord=9
 write GribCollectionIndex= 35929 bytes</pre>
<p>There are a total of 3.6M grib records, but only 132K are unique and used in the collection dataset. This is typical when making a collection of forecast model runs, where the forecast times heavily overlap.</p>
<p>When opening the collection dataset, only 36K has to be read in. The remaining bytes of the 1.26M collection index are the record lookup section, and are read in only when a variable's data is requested.</p>
<p>In this example, computing the collection index takes around 60 sec,  with 4Gb heap space, but 30 minutes with 2Gb heap. That probaby means that the index took just under 2Gb heap and was doing excessive GC. So one needs large heap sizes to compute these large collections.</p>
<h3>Assumptions on the GRIB encoding</h3>
<p>The collection of GRIB records is not arbitrary, but must be coherent (eg come all from the same model) such that the following assumptions are valid:</p>
<ol>
  <li>All Grib records are assumed to have the same center, subcenter, and master and local table versions. This is used for determiing which GRIB code and template tables to use.</li>
  <li>Grib records can be distributed arbitrarily among the collection of files.</li>
  <li>Unique variables are created by hashing the<em> GDS, PDS template, discipline, category, parameter, </em> <em>level type</em>, and <em>level layer flag</em>. Also, if they apply, the<em> statistical process type</em> (code table 4.10), and the <em>ensemble derived type</em>  (table 4.7).</li>
  <li>The collection of GRIB records for each unique variable is turned into a multidimensional grid, by taking the cartesion product of<strong><em> time X ens X vert </em></strong>coordinates. Where there are missing records, the library will return missing data. Where there are duplicate records, later records replace earlier records, where later means later in one file, or in a later file where the file collection is sorted lexigraphically.</li>
  <li>If there are multiple GDS (Grid Definition Section) in the collection, each unique GDS and the variables that use it becomes a seperate <em>Group</em>. GDS uniqueness is based on a hashcode. Unfortunately, there may be roundoff errors and/or minor variations in GDS encodings. The CDM tries to allow for this in <em>Grib2Gds.hashcode()</em>. If you see variables unexpectedly split into different groups with apparently the same projection, likely the hashcode for that projection type needs to be modified.</li>
  <li>All of the  time, ensemble, and vertical coordinates for each variable in one group are compared, and where they are identical, are shared between variables.</li>
</ol>
<h3>RAF Caching</h3>
<pre>    // GribCollection : default is allow 100 - 200 open files, cleanup every 15 minutes<br />    min = ThreddsConfig.getInt(&quot;GribCollection.minFiles&quot;, 100);<br />    max = ThreddsConfig.getInt(&quot;GribCollection.maxFiles&quot;, 200);<br />    secs = ThreddsConfig.getSeconds(&quot;GribCollection.scour&quot;, 15 * 60);<br />    if (max &gt; 0) {<br />      GribCollection.initFileCache(min, max, secs);<br />      startupLog.info(&quot;CdmInit: GribCollection.initFileCache= [&quot;+min+&quot;,&quot;+max+&quot;] scour = &quot;+secs);<br />    }</pre>
<p>&nbsp;</p>
<h2>Time Partitions</h2>
<p>&nbsp;</p>
<pre>// date matcher part of spec - #date# - can only be in name
// time partition by directory

&lt;collection spec=&quot;G:/nomads/cfsr/timeseries/**/.*grb2$&quot; dateFormatMark=&quot;#timeseries/#yyyyMM&quot; name=&quot;CFSR-timeseries&quot; timePartition=&quot;directory&quot; /&gt;

      
// dateFormatMark in seperate attribute - #match literal# - works on the path
// time partition by day
        &lt;collection<br />            spec=&quot;/data/ldm/pub/native/grid/NCEP/SREF/CONUS_40km/ensprod_biasc/.*grib2$&quot;<br />            name=&quot;SREF_CONUS_40km_ensprod_biasc&quot;<br />            dateFormatMark=&quot;#SREF_CONUS_40km_ensprod_biasc_#yyyyMMdd_HHmm&quot;<br />            timePartition=&quot;day&quot;<br />            olderThan=&quot;5 min&quot;/&gt;






// date matcher part of spec - #date# - can only be in name

  &lt;collection<br />            spec=&quot;/data/ldm/pub/native/grid/NCEP/SREF/CONUS_40km/pgrb_biasc/SREF_CONUS_40km_pgrb_biasc_[a-z]*_#yyyyMMdd_HHmm#.grib2$&quot;<br />            name=&quot;SREF_CONUS_40km_ensprod_biasc&quot;<br />            timePartition=&quot;day&quot;<br />            olderThan=&quot;5 min&quot;/&gt;

        &lt;collection<br />            spec=&quot;/data/ldm/pub/native/grid/NCEP/SREF/CONUS_40km/pgrb_biasc/.*grib2$&quot;<br />            name=&quot;SREF_CONUS_40km_ensprod_biasc&quot;<br />            dateFormatMark=&quot;yyyyMMdd_HHmm#.grib2#&quot;<br />            timePartition=&quot;day&quot;<br />            olderThan=&quot;5 min&quot;/&gt;<br />
 </pre>
<p>&nbsp;</p>
<p>cannot mix ensembles and vertical levels across the partition.</p>
<p> for each variable, create union of times: for each time track (value, partition, localIndex). merge time coords with same {value}. store {partition, localIndex} cmmon case is that variables will share  {partition, localIndex}, but is it worth merging?</p>
<p>dont need proto change; its reselected when index is rebuilt</p>
<h2>check for changes</h2>
<p>handled by DCM, looking only at underlying collection.</p>
<h3>GribCollection</h3>
<ol>
  <li>look for new or deleted files</li>
  <li>look if newFile.lastModified()  &gt; oldFile.lastModified() </li>
  <li>look if index (gbx9) file doesnt exist, or has lastModified date   &lt; oldFile.lastModified() </li>
</ol>
<p>&nbsp;</p>
<p>cant examine all files to see whats changed - too mant files. only examine each partition. maybe examine the latest?? maybe not - use manual rescan ??</p>
<hr width="100%" />
<address>
<img src="../../../images/thread.png" alt="" width="76" height="67" /> This document is maintained by <a href="mailto:caron@unidata.ucar.edu">John Caron</a> and was last updated  Dec 2011
</address>
</body>
</html>
