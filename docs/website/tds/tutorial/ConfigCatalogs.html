<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <title>TDS Configuration Catalogs</title>
  <link rel="stylesheet" href="tutorial2.css" type="text/css"/>
  <script type="text/javascript" src="workshopNav.js"></script>
</head>
<body>
<h1>TDS Configuration Catalogs</h1>

<div id="section">
  <h2><a name="serviceElement">The <code>service</code> Element</a></h2>

  <h3>Compound <code>service</code> Elements - Serving Datasets with Multiple Methods</h3>

  <p>Datasets can be made available through more than one access method by defining and then referencing a <strong>compound</strong> <code>service</code> element. The
    following: </p>

<pre>
&lt;service name="<strong>all</strong>" base="" serviceType="Compound" &gt;
    &lt;service name="odap" serviceType="OPeNDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="http" serviceType="FileServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
</pre>

  <p>defines a compound service named "all" which contains two nested services. Any dataset that reference the compound service will have two access methods.
    For instance: </p>

  <pre>
&lt;datasetRoot path="precip" location="/machine/tds/data/precip" /&gt;
&lt;dataset name="Precip Data" ID="precipdata" urlPath="precip/nws_precip_conus_20130909.nc"
    dataType="Grid" serviceName="all" /&gt;</pre>

  <p>would result in these two access URLs:</p>

  <pre><code>/thredds/dodsC/precip/nws_precip_conus_20130909.nc
/thredds/fileServer/precip/nws_precip_conus_20130909.nc</code></pre>

  <p>Note: The contained services can still be referenced independently. For instance:</p>

  <pre>&lt;dataset name="More Precip Data" ID="precipdata2" urlPath="precip/nws_precip_conus_20130910.nc"
    dataType="Grid" serviceName="odap" /&gt;</pre>

  <p>results in a single access URL:</p>

  <pre><code>/thredds/dodsC/precip/nws_precip_conus_20130910.nc</code></pre>

  <div id="note" class="info">
    <h4>Unique Service Names</h4>
    <ol class="little">
      <li>Service names do not have to be unique globally within a TDS, only on a catalog by catalog basis.</li>
      <li>Duplicate service names do not adversely affect the TDS. However, clients reading a catalog with
        duplicate service names may get confused if a dataset references that service name.
      </li>
    </ol>
  </div>

  <p>Using compound services allow maintaining groups of services across datasets, rather than needing to maintain individual lists with each dataset. For instance,
  we can add the DAP4 service to the above <code>all</code> service:</p>

<pre>...
&lt;service name="<strong>all</strong>" base="" serviceType="Compound" &gt;
    &lt;service name="odap" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="dap4" serviceType="DAP4" base="/thredds/dap4/" /&gt;
    &lt;service name="http" serviceType="FileServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
...</pre>

  <p>This would then add an additional access URL for DAP4:</p>

  <pre><code>/thredds/dap4/precip/nws_precip_conus_20130909.nc</code></pre>

  <h3>Unique Names Required for each <code>service</code> Element in a Catalog</h3>

  <p>Service names are used by datasets to reference the <code>service</code> element that represents the available service(s) for that dataset. So that the
    service reference resolves to a unique <code>service</code> element, all service names within a given catalog must be unique.</p>

  <p>Here's an example:</p>

<pre>
...
&lt;service name="any" serviceType="Compound" base="" &gt;
    &lt;service name="<strong>service1</strong>" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="<strong>service2</strong>" serviceType="HTTPServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
&lt;service name="grid" serviceType="Compound" base="" &gt;
    &lt;service name="<strong>service1</strong>" serviceType="OpenDAP" base="/thredds/dodsC/" /&gt;
    &lt;service name="<strong>service2</strong>" serviceType="WCS" base="/thredds/wcs/" /&gt;
    &lt;service name="service3" serviceType="WMS" base="/thredds/wms/" /&gt;
    &lt;service name="service4" serviceType="HTTPServer" base="/thredds/fileServer/" /&gt;
&lt;/service&gt;
...
</pre>
  <div id="expanded" class="troubleshooting">
    <h4>Notes:</h4>
    <ul>
      <li>A dataset that references "<code>service1</code>" will be fine. But only because both "<code>service1</code>" instances have the same <code>serviceType</code>
        and <code>base</code> URL.
      </li>
      <li>A dataset that references "<code>service2</code>" may find either the HTTP file service or the WCS service.</li>
    </ul>
  </div>
</div>
<!-- end section -->



<div id="section">
  <h2><a name="requirements">TDS Requirements for the <code>service</code> Elements</a></h2>

  <p>The TDS provides data access services at predefined URL base paths. Therefore, it is <strong>required that service base URLs must exactly match the values given
    here</strong> according to service type: </p>

  <h3>OPeNDAP</h3>
  <pre>&lt;service name="odap" serviceType="OPeNDAP" base="<strong>/thredds/dodsC/</strong>"&nbsp;/&gt;</pre>

  <h3>NetCDF Subset Service</h3>
  <pre>&lt;service name="ncss" serviceType="NetcdfSubset" base="<strong>/thredds/ncss/</strong>"&nbsp;/&gt;</pre>

  <h3>WCS</h3>
  <pre> &lt;service name="wcs" serviceType="WCS" base="<strong>/thredds/wcs/</strong>"&nbsp;/&gt;</pre>

  <h3>WMS</h3>
  <pre> &lt;service name="wms" serviceType="WMS" base="<strong>/thredds/wms/</strong>"&nbsp;/&gt;</pre>

  <h3>HTTP Bulk File Service</h3>
  <pre>&lt;service name="fileServer" serviceType="HTTPServer" base="<strong>/thredds/fileServer/"</strong>&nbsp;/&gt;</pre>

  <p>Notes: These base URLs are relative to the server so your catalogs are independent of your servers hostname or port.</p>

  <div id="expanded" class="troubleshooting">
    <h4>Data Requirement for Each Service</h4>
    <ul>
      <li>The <strong>"HTTPServer"</strong> service can serve any file.</li>
      <li>The <strong>"OPeNDAP"</strong> service can serve any data file that the netCDF-Java library can open.</li>
      <li>The <strong>"WCS"</strong> service can only serve data files that the netCDF-Java library can recognize as "gridded" data.</li>
      <li>The <strong>"WMS"</strong> service also only serves "gridded" data files.</li>
      <li>The <strong>"NetcdfSubset"</strong> service also only serves "gridded" data files.</li>
    </ul>
  </div>

  <p>You can check that a data file is recognized as "gridded" with netCDF-Java ToolsUI (available for download from the
    <a href="http://www.unidata.ucar.edu/software/netcdf-java/">netCDF-Java home page</a> or you can use
    <a href="https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/webstart/netCDFtools.jnlp">webstart</a>).</p>

  <div id="expanded" class="exercise">
    <h3>Exercise: Check that the NAM Dataset is Gridded Data</h3>
    <ol>
      <li>Open the netCDF-Java ToolsUI application [<a href="https://www.unidata.ucar.edu/software/thredds/current/netcdf-java/webstart/netCDFtools.jnlp">webstart</a>].
      </li>
      <li>In the "FeatureTypes" - "Grids" tab, browse to the <code>/machine/tds/data/nam_12km</code> directory and open a dataset file.</li>
      <li>If variables are listed in the top section of the window, the netCDF-Java library has recognized the dataset as gridded data.</li>
    </ol>
    <p><strong>Note</strong>: While you have ToolsUI open, take a look at the "Viewer" tab and the "THREDDS" tab</p>

    <p>The "Viewer" tab supports inspection of the dataset at the netCDF/CDM Data Access level (i.e., dimensions, variables, and attributes).</p>

    <p>The "THREDDS" tab supports browsing of THREDDS catalogs and selection of datasets.</p>
  </div>

</div>
<!-- end section -->


<div id="section">
  <h2><a name="metadata">THREDDS Metadata</a></h2>


  <h3>Linking to Metadata</h3>
  <pre>&lt;metadata xlink:title="some good metadata" xlink:href="http://my.server/md/data1.xml" /&gt;</pre>

  <h3>Linking to Human Readable Metadata</h3>
  <pre>&lt;documentation xlink:title="My Data" xlink:href="http://my.server/md/data1.html" /&gt;</pre>

  <h3>Inherited Metadata</h3>
<pre>
...
  &lt;dataset name="Precip Set"&gt;

    &lt;metadata inherited="true"&gt;
      &lt;serviceName&gt;all&lt;/serviceName&gt;
      &lt;description&gt;Multi-sensor precipitation estimates&lt;/description&gt;
      &lt;keyword&gt;Precipitation&lt;/keyword&gt;
      &lt;creator&gt;
        &lt;name&gt;National Weather Service&lt;/name&gt;
	&lt;contact url="http://water.weather.gov/precip/" email="AHPS.Precip@noaa.gov" /&gt;
      &lt;/creator&gt;
      &lt;dataType&gt;Grid&lt;/dataType&gt;
    &lt;/metadata&gt;

    &lt;dataset name="Precip Data" ID="precip1" urlPath="precip/nws_precip_conus_20130909.nc"&gt;
      &lt;date type="created"&gt;2013-09-09&lt;/date&gt;
    &lt;/dataset&gt;

    <strong>&lt;dataset name="More Precip Data" ID="precip2" urlPath="precip/nws_precip_conus_20130910.nc"&gt;</strong>

      &lt;metadata&gt;
	&lt;serviceName&gt;odap&lt;/serviceName&gt;
        &lt;date type="created"&gt;2013-09-10&lt;/date&gt;
      &lt;/metadata&gt;

    &lt;/dataset&gt;

  &lt;/dataset&gt;
...
</pre>

  <div id="expanded" class="troubleshooting">
    <h4>Notes:</h4>

    <p><strong>1)</strong> Child datasets inherit the netCDF dataFormat element</p>

    <p><strong>2)</strong> This child's inherited metadata is overridden.</p>
  </div>

<p>The datasetScan element is an extension of the dataset element and so can contain metadata.</p>

<pre>
...
      &lt;datasetScan name="Precip Set" ID="precipset"
                   path="<strong>precip</strong>" location="/machine/tds/data/precip/"&gt;
          &lt;metadata inherited="true"&gt;
              &lt;serviceName&gt;all&lt;/serviceName&gt;
	      &lt;documentation&gt;Multi-sensor precipitation estimates&lt;/documentation&gt;
              &lt;keyword&gt;Precipitation&lt;/keyword&gt;
              &lt;creator&gt;
                &lt;name&gt;National Weather Service&lt;/name&gt;
	        &lt;contact url="http://water.weather.gov/precip/" email="AHPS.Precip@noaa.gov" /&gt;
              &lt;/creator&gt;
              &lt;dataType&gt;Grid&lt;/dataType&gt;
              &lt;date type="created"&gt;2013&lt;/date&gt;
          &lt;/metadata&gt;
      &lt;/datasetScan&gt;
...
</pre>

<p>The client view of the above datasetScan element will be a catalogRef element
  which will also contain any metadata contained in the datasetScan element. It will
  look something like:</p>
<pre>
&lt;catalogRef xlink:href="/thredds/catalog/<strong>precipscan</strong>/catalog.xml"
               xlink:title="Precip Set" ID="precipset" name=""&gt;
    &lt;metadata inherited="true"&gt;
        ...
    &lt;/metadata&gt;
&lt;/catalogRef &gt;
</pre>

<p>All generated catalogs that are descendants of this datasetScan will contain all inherit-able (inherited="true") metadata contained in the datasetScan
  element. For instance, given that the <code>precip</code> directory contained five files,
  the resulting child catalog will look like:</p>

<pre>
  &lt;service name="all" serviceType="Compound" base=""&gt;
    &lt;service name="odap" serviceType="OPENDAP" base="/thredds/dodsC/"/&gt;
    &lt;service name="dap4" serviceType="DAP4" base="/thredds/dap4/"/&gt;
    &lt;service name="http" serviceType="HTTPServer" base="/thredds/fileServer/"/&gt;
  &lt;/service&gt;
  &lt;dataset name="Precip Set" ID="precipset"&gt;
    &lt;metadata inherited="true"&gt;
      &lt;serviceName&gt;all&lt;/serviceName&gt;
      &lt;dataType&gt;GRID&lt;/dataType&gt;
      &lt;documentation&gt;Multi-sensor precipitation estimates&lt;/documentation&gt;
      &lt;creator&gt;
        &lt;name&gt;National Weather Service&lt;/name&gt;
        &lt;contact url="http://water.weather.gov/precip/" email="AHPS.Precip@noaa.gov"/&gt;
      &lt;/creator&gt;
    &lt;keyword&gt;Precipitation&lt;/keyword&gt;
    &lt;date type="created"&gt;2013&lt;/date&gt;
    &lt;/metadata&gt;
    &lt;dataset name="nws_precip_conus_20130913.nc" ID="precipset/nws_precip_conus_20130913.nc"
          urlPath="precipscan/nws_precip_conus_20130913.nc"&gt;
      &lt;dataSize units="Mbytes"&gt;1.710&lt;/dataSize&gt;
      &lt;date type="modified"&gt;2014-10-16T16:19:53Z&lt;/date&gt;
    &lt;/dataset&gt;
    &lt;dataset name="nws_precip_conus_20130912.nc" ID="precipset/nws_precip_conus_20130912.nc"
          urlPath="precipscan/nws_precip_conus_20130912.nc"&gt;
      &lt;dataSize units="Mbytes"&gt;1.710&lt;/dataSize&gt;
      &lt;date type="modified"&gt;2014-10-16T16:19:53Z&lt;/date&gt;
    &lt;/dataset&gt;
    &lt;dataset name="nws_precip_conus_20130911.nc" ID="precipset/nws_precip_conus_20130911.nc"
          urlPath="precipscan/nws_precip_conus_20130911.nc"&gt;
      &lt;dataSize units="Mbytes"&gt;1.710&lt;/dataSize&gt;
      &lt;date type="modified"&gt;2014-10-16T16:19:53Z&lt;/date&gt;
    &lt;/dataset&gt;
    &lt;dataset name="nws_precip_conus_20130910.nc" ID="precipset/nws_precip_conus_20130910.nc"
          urlPath="precipscan/nws_precip_conus_20130910.nc"&gt;
      &lt;dataSize units="Mbytes"&gt;1.710&lt;/dataSize&gt;
      &lt;date type="modified"&gt;2014-10-16T16:19:53Z&lt;/date&gt;
    &lt;/dataset&gt;
    &lt;dataset name="nws_precip_conus_20130909.nc" ID="precipset/nws_precip_conus_20130909.nc"
          urlPath="precipscan/nws_precip_conus_20130909.nc"&gt;
      &lt;dataSize units="Mbytes"&gt;1.710&lt;/dataSize&gt;
      &lt;date type="modified"&gt;2014-10-16T16:19:53Z&lt;/date&gt;
    &lt;/dataset&gt;
  &lt;/dataset&gt;
</pre>
</div>

<!-- end section -->

<div id="section">
<h2><a name="config">TDS Configuration Catalogs</a></h2>

<h3>Tools to Manage Configuration Catalogs </h3>

<p>First, the TDS catalog initialization log</p>
<pre>&lt;tds.content.root.path&gt;/thredds/logs/catalogInit.log</pre>

<p>contains all warning and error messages from parsing the configuration catalogs. As such, it is a great place to look for
  information if you run into problems with your TDS configuration catalogs.</p>

<p>Second, the TDS Remote Management page provides access to a list of all the configuration catalogs the TDS has successfully
  read:</p>
<ul>
  <li>From the TDS Remote Management page [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>]:</li>
  <p><img src="images/TdsRemoteManager_top.png" alt="TDS Remote Management page (top)" width="618" height="685"></p>
  </li>
  <li>Click on the "Show static catalogs" link:</li>
  <p><img src="images/TdsRemoteManager_staticCatalogs.png" alt="List of Static Catalogs" width="738" height="502"></p>
  </li>
</ul>


<h3>Managing <code>datasetRoot</code> and <code>datasetScan</code> Elements</h3>

<p>You can have as many datasetRoot and datasetScan elements as you want, for example </p>

<pre>
&lt;datasetRoot path="<strong>model</strong>" location="<strong>/data/ncep</strong>" /&gt;
&lt;datasetRoot path="<strong>obs</strong>" location="<strong>/data/raw/metars</strong>" /&gt;
&lt;datasetRoot path="<strong>cases/001</strong>" location="<strong>C:/casestudy/data/001</strong>" /&gt;
&lt;datasetScan path="<strong>myData</strong>" location="<strong>/data/ncep/run0023</strong>" name="NCEP/RUN 23" serviceName="myserver" /&gt;
&lt;datasetScan path="<strong>myData/gfs</strong>" location="<strong>/pub/ldm/gfs</strong>" name="NCEP/GFS" serviceName="myserver" /&gt;
</pre>

<p>The datasetRoot and datasetScan are said to define a <strong>data root</strong>.</p>

<div id="expanded" class="troubleshooting">
  <h4>The Rules for Data Roots</h4>
  <ul>
    <li>Each accessible dataset must be associated with a data root, i.e. the beginning part of its URL path must match a data root path. If there are multiple
      matches, the longest match is used.
    </li>
    <li><strong>Each data root must have a unique <code>path</code> for all catalogs used by the TDS.</strong></li>
    <p>Note: Because the TDS uses the set of all given path values to map URLs to datasets, each path value MUST be unique across all config catalogs on a given
      TDS installation. Duplicates will cause warning messages in the <code>catalogInit.log</code> file.</p>
    <li>The directory pointed to by <strong>location</strong> should be absolute</li>
    <li>The locations may be used in multiple data roots</li>
  </ul>
</div>

<p>For example, using the above data roots, the following matches would be made:</p>

<table style="width: 611px; height: 150px;" border="1">
  <tbody>
  <tr>
    <th scope="col" width="238">urlPath</th>
    <th scope="col" width="357">file</th>
  </tr>
  <tr>
    <td><code><strong>model</strong>/run0023/mydata.nc</code></td>
    <td><code><strong>/data/ncep</strong>/run0023/mydata.nc</code></td>
  </tr>
  <tr>
    <td><code><strong>obs</strong>/test.nc</code></td>
    <td><code><strong>/data/raw/metars</strong>/test.nc</code></td>
  </tr>
  <tr>
    <td><code><strong>myData</strong>/mydata.nc</code></td>
    <td><code><strong>/data/ncep/run0023</strong>/mydata.nc</code></td>
  </tr>
  <tr>
    <td><code><strong>myData/gfs</strong>/mydata.nc</code></td>
    <td><code><strong>/pub/ldm/gfs</strong>/mydata.nc</code></td>
  </tr>
  <tr>
    <td><code><strong>cases/001</strong>/test/area/two</code></td>
    <td><code><strong>C:/casestudy/data/001</strong>/test/area/two</code></td>
  </tr>
  </tbody>
</table>

<p>The structure of a full OPeNDAP URL for the first urlPath above would
  look like:</p>

<pre>
http://hostname:port/thredds/dodsC/model/run0023/mydata.nc
|&lt;---  server   ---&gt;|&lt;-----&gt;|&lt;---&gt;|&lt;---&gt;|&lt;-   filename  -&gt;|
                        |      |     |
           webapp name -|      |     |- data root
                               |
                      service -|
</pre>

<p>where:</p>
<ul>
  <li><strong>http://hostname:port</strong> is the server's hostname and port. By using relative service base URLs, you never have to specify this explicitly in your
    catalogs. This means you can change hosts or ports without having to rewrite your catalogs.
  </li>
  <li><strong>/thredds</strong> is the name of the <em><strong>web application</strong></em>, taken from the <strong>thredds.war</strong> file.</li>
  <li><strong>/dodsC</strong> maps to the servlet inside the web application, here it would be the <strong>OPeNDAP</strong> servlet.</li>
  <li><strong>/model</strong> is the <em>path</em>, associated with the directory location <strong>/data/ncep/</strong>.</li>
  <li><strong>/run0023/mydata.nc</strong> is the relative filename, and so is mapped to <strong>/data/ncep</strong>/<strong>run0023/mydata.nc</strong>.</li>
</ul>

<h3>TDS Remote Management - List of Dataset Roots</h3>

<p>The TDS Remote Management page has a link to list all known dataset roots:</p>
<ul>
  <li>Go to the TDS Remote Management page [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>]</li>
  <li>Click on the "Show data roots" link</li>
  <p>
    <img src="images/TdsRemoteManager_dataRoots.png" alt="TDS Remote Management - List of Data Roots" width="864" height="480" style="width: 635px; height: 359px;">
  </p>
</ul>

<div id="expanded" class="exercise">
  <h3>Exercise: Managing multiple roots</h3>

  <p>Add a few more datasetScan elements:</p>
  <ol>
    <li>Check the /machine/tds/data/ocean, /machine/tds/data/gfs, and /machine/tds/data/nam_12km data directories:</li>
    <pre><strong>$</strong> ls /machine/tds/data/<br>fc/  gfs/  nam_12km/  ocean/  precip/</pre>
       <pre><strong>$</strong> ls /machine/tds/data/gfs
GFS_CONUS_95km_20141010_0000.grib2  GFS_CONUS_95km_20141011_1800.grib2  GFS_CONUS_95km_20141013_1200.grib2
GFS_CONUS_95km_20141010_0600.grib2  GFS_CONUS_95km_20141012_0000.grib2  GFS_CONUS_95km_20141013_1800.grib2
GFS_CONUS_95km_20141010_1200.grib2  GFS_CONUS_95km_20141012_0600.grib2  GFS_CONUS_95km_20141014_0000.grib2
GFS_CONUS_95km_20141010_1800.grib2  GFS_CONUS_95km_20141012_1200.grib2  GFS_CONUS_95km_20141014_0600.grib2
GFS_CONUS_95km_20141011_0000.grib2  GFS_CONUS_95km_20141012_1800.grib2  GFS_CONUS_95km_20141014_1200.grib2
GFS_CONUS_95km_20141011_0600.grib2  GFS_CONUS_95km_20141013_0000.grib2  GFS_CONUS_95km_20141014_1800.grib2
GFS_CONUS_96km_20141011_1200.grib2  GFS_CONUS_95km_20141013_0600.grib2</pre>
       <pre><strong>$</strong> ls /machine/tds/data/nam_12km
NAM_CONUS_12km_20141010_0000.grib2  NAM_CONUS_12km_20141011_1800.grib2  NAM_CONUS_12km_20141013_1200.grib2
NAM_CONUS_12km_20141010_0600.grib2  NAM_CONUS_12km_20141012_0000.grib2  NAM_CONUS_12km_20141013_1800.grib2
NAM_CONUS_12km_20141010_1200.grib2  NAM_CONUS_12km_20141012_0600.grib2  NAM_CONUS_12km_20141014_0000.grib2
NAM_CONUS_12km_20141010_1800.grib2  NAM_CONUS_12km_20141012_1200.grib2  NAM_CONUS_12km_20141014_0600.grib2
NAM_CONUS_12km_20141011_0000.grib2  NAM_CONUS_12km_20141012_1800.grib2  NAM_CONUS_12km_20141014_1200.grib2
NAM_CONUS_12km_20141011_0600.grib2  NAM_CONUS_12km_20141013_0000.grib2
NAM_CONUS_12km_20141011_1200.grib2  NAM_CONUS_12km_20141013_0600.grib2</pre>
       <pre><strong>$</strong> ls /machine/tds/data/ocean
OCEAN_Global_5x2p5deg_20141010_0000.nc  OCEAN_Global_5x2p5deg_20141012_1200.nc
OCEAN_Global_5x2p5deg_20141010_1200.nc  OCEAN_Global_5x2p5deg_20141013_0000.nc
OCEAN_Global_5x2p5deg_20141011_0000.nc  OCEAN_Global_5x2p5deg_20141013_1200.nc
OCEAN_Global_5x2p5deg_20141011_1200.nc  OCEAN_Global_5x2p5deg_20141014_0000.nc
OCEAN_Global_5x2p5deg_20141012_0000.nc  OCEAN_Global_5x2p5deg_20141014_1200.nc</pre>
    <li>Edit the main TDS configuration catalog:
<pre>
<strong>$</strong> cd ${tomcat_home}/content/thredds
<strong>$</strong> vi catalog.xml     <var>// Use the editor of your choice</var>
</pre>
    </li>
    <li>And add a <code>datasetScan</code> element for the GFS output:
<pre>
&lt;datasetScan name="<strong>GFS</strong>" ID="<strong>GFS</strong>"
             path="<strong>gfs</strong>" location="<strong>/machine/tds/data/gfs</strong>"&gt;

    &lt;metadata inherited="true"&gt;
        &lt;serviceName&gt;all&lt;/serviceName&gt;
    &lt;/metadata&gt;<br>
&lt;/datasetScan&gt;
</pre>
    </li>
    <li>And similarly for NAM (12km) and Ocean output</li>
    <li>Restart Tomcat so the TDS is reinitialized:
<pre>
<strong>$</strong> cd ${tomcat_home}/bin
<strong>$</strong> ./shutdown.sh
<strong>$</strong> ./startup.sh
</pre>
    </li>
    </li>
    <li>Test that the new <code>datasetScan</code> elements are working:
      <ol>
        <li>Bring the catalog up in a browser:
          <code><a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a></code>
        </li>
        <li>Browse into the new dataset collections.
        </li>
        <li>Try an OPeNDAP access method link</li>
      </ol>
    </li>
  </ol>
  <p>Now that we have multiple dataset roots ...</p>
  <ol>
    <li>Lets check the list of dataset roots:</li>
    <ol>
      <li>
        Go back to the TDS Remote Management page:
        <code>
          <a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>
        </code>
      </li>
      <li>Select the "Show data roots" link.</li>
    </ol>
    <li>Check the catalogInit.log:
      <ol>
        <li>TDS Remote Management page
          [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>]
        </li>
        <li>Click the "Show TDS Logs" link.</li>
        <li>Select the "catalogInit.log" file</li>
      </ol>
    </li>
  </ol>
</div>

<div id="expanded" class="exercise">
  <h3>Exercise: Duplicate Roots</h3>
  <ol>
    <li>
      Modify the GFS <code>datasetScan</code> element so that the value of the
      path attribute matches the one for the NAM (12km) <code>datasetScan</code>
      element.
<pre>
<strong>$</strong> cd ${tomcat_home}/content/thredds
<strong>$</strong> vi catalog.xml     <var>// Use the editor of your choice</var>
</pre>
    </li>
    <li>Restart Tomcat so the TDS is reinitialized:
<pre>
<strong>$</strong> cd ${tomcat_home}/bin
<strong>$</strong> ./shutdown.sh
<strong>$</strong> ./startup.sh
</pre>
    </li>
    <li>What happens with duplicate data roots:
      <ol>
        <li>
          Browse into the GFS dataset
          [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
        </li>
        <li>Check the list of dataset roots
          [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a> - click on "Check data roots"]
        </li>
        <li>Check the catalogInit.log
          [<a href="http://localhost:8080/thredds/admin/debug">http://localhost:8080/thredds/admin/debug</a>
          - click on "Show TDS Logs"]
        </li>
      </ol>
    </li>
    <li>Now fix the GFS datasetScan element.</li>
  </ol>
</div>
</div>
<!-- end section -->


<div id="section">
  <h2><a name="DatasetScan">More <code>datasetScan</code> Element</a></h2>

  <h3>Including Only the Desired Files</h3>

  <p>A <code>datasetScan</code> element can specify which files and directories it will include with a <code>filter</code> element (see
    <a href="../catalog/InvCatalogServerSpec.html#filter_Element">spec</a> for more details). When no <code>filter</code> element is given, all files
    and directories are included in the generated catalog(s). Adding a <code>filter</code> element to your <code>datasetScan</code> element allows you to
    include (and/or exclude) the files and directories as desired. The <code>datasetScan</code> element for the NAM (12km) example included the following:</p>
  <pre>&lt;filter&gt;<br>    &lt;include wildcard="*.grib2" /&gt;<br>&lt;/filter&gt;<br></pre>

  <p>To exclude the 00Z runs, the filter could be modified to:</p>
  <pre>&lt;filter&gt;<br>    &lt;include wildcard="*.grib2" /&gt;<br>    &lt;exclude wildcard="*0000.grib2" /&gt;<br>&lt;/filter&gt;</pre>

  <p>The <code>include</code> and <code>exclude</code> elements both determine which datasets they match on whether their wildcard pattern (given by the <code>wildcard</code>
    attribute) or <a href="http://www.regular-expressions.info/">regular expression</a> (given by the <code>regExp</code> attribute) match the dataset name. By
    default, includes and excludes apply only to regular files (atomic datasets). You can specify that they apply to directories (collection datasets) as well
    by using the <code>atomic</code> and <code>collection</code> attributes. For example, if the nam_12km directory contained a badData directory, I could
    exclude it by adding the following to the filter: </p>
  <pre>&lt;exclude wildcard="badData" atomic="false" collection="true" /&gt;</pre>

  <div id="expanded" class="exercise">
    <h3>Exercise: Filtering Files</h3>
    <ol>
      <li>Browse one of the datasets you just added and find a
        "<strong>.scour</strong>" file. Try the OPeNDAP access method:
<pre>
Error {
    code = 500;
    message = "Cant read /machine/tds/data/gfs/.scour: not a valid NetCDF file.";
};
</pre>
      </li>
      <li>Now add a <code>filter</code> element to the <code>datasetScan</code>
        elements. Something like:
<pre>
&lt;filter&gt;
    &lt;include wildcard="<strong>*.nc</strong>" /&gt;
    &lt;include wildcard="<strong>*.grib1</strong>" /&gt;
    &lt;include wildcard="<strong>*.grib2</strong>" /&gt;
&lt;/filter&gt;
</pre>
      </li>
      <li>Restart Tomcat so the TDS is reinitialized:
<pre>
<strong>$</strong> cd ${tomcat_home}/bin
<strong>$</strong> ./shutdown.sh
<strong>$</strong> ./startup.sh
</pre>
      </li>
      <li>
        Are the filters working?
        [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
      </li>
    </ol>
  </div>
  <div id="expanded" class="exercise">
    <h3>Exercise: Filtering Directories</h3>
    <ol>
      <li>Browse around in the "ocean" dataset.</li>
      <li>Add a <code>filter</code> element to the "ocean" <code>datasetScan</code>
        element to exclude the "2013" directory. Something like:
<pre>
&lt;exclude wildcard="<strong>2013</strong>" atomic="false" collection="true" /&gt;
</pre>
      </li>
      <li>Restart Tomcat so the TDS is reinitialized:
<pre>
<strong>$</strong> cd ${tomcat_home}/bin
<strong>$</strong> ./shutdown.sh
<strong>$</strong> ./startup.sh
</pre>
      </li>
      <li>
        Are the filters working?
        [<a href="http://localhost:8080/thredds/catalog.html">http://localhost:8080/thredds/catalog.html</a>]
      </li>
    </ol>
  </div>


  <h3>Sorting Datasets</h3>

  <p>By default, datasets are listed in decreasing lexigraphic order by the dataset name. A <code>sort</code> element can be added to a <code>datasetScan</code>
    element to specify an increasing lexigraphic order:</p>
  <pre>&lt;sort&gt;<br>    &lt;lexigraphicByName increasing="true" /&gt;<br>&lt;/sort&gt;</pre>
  <p> Currently, the lexigraphic increasing or decreasing sort algorithm is the only one supported.</p>

  <h3>Dataset IDs</h3>

  <p>All generated datasets are given an ID. The IDs are simply the path of the dataset appended to the datasetScan path value or, if one exists, the ID of the
    datasetScan element. So, for the <code>nam_12km</code> directory and our current configuration:</p>

    <pre>
&lt;datasetScan name="NCEP NAM 12km" ID="<strong>nam</strong>"
             path="nam" location="/machine/tds/data/nam_12km"&gt;</pre>

  <p>and for the data file NAM_CONUS_12km_20141010_0000.grib2, the value of the dataset ID would be "NAM_12km/NAM_CONUS_12km_20141010_0000.grib2".</p>

  <h3><a name="Naming_Datasets"></a>Naming Datasets</h3>

  <p> By default, all datasets are named with the name of their underlying file. By adding a <code>namer</code> element, you can specify more human readable
    dataset names. For instance, the following <code>namer</code> element causes any dataset named "NCEP NAM_12km" to be
    renamed with the value of <code>replaceString</code>:</p>

    <pre>
&lt;namer&gt;
  &lt;regExpOnName regExp="NCEP NAM 12km" replaceString="NCEP NAM 12km model output" /&gt;
&lt;/namer&gt;</pre>

  <div id="note" class="info">
    <h4>Naming: New Name Does Not Affect Other Operations</h4>

    <p>While renaming datasets can be used to make the resulting dataset name more human readable, the renaming does not affect the behavior of any of the other
      datasetScan operations (filtering, sorting, etc.). All datasetScan operations that use or modify the dataset name use the name of the underlying dataset,
      e.g., the data file on disk. </p>
  </div>

  <p>More complex renaming is possible as well. The namer uses a <a href="http://www.regular-expressions.info/">regular expression</a> match on the dataset
    name. If the match succeeds, any regular expression <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg">capturing groups</a>
    are used in the replacement string.</p>

  <p>A capturing group is a part of a regular expression enclosed in parenthesis. When a regular expression with a capturing group is applied to a string, the
    substring that matches the capturing group is saved for later use. The captured strings can then be substituted into another string in place of capturing
    group references,"$n", where "n" is an integer indicating a particular capturing group. (The capturing groups are numbered according to the order in which
    they appear in the match string.) For example, the regular expression "Hi (.*), how are (.*)?" when applied to the string "Hi Fred, how are you?" would
    capture the strings "Fred" and "you". Following that with a capturing group replacement in the string "$2 are $1." would result in the string "you are
    Fred."</p>

  <p>Here's an example namer:</p>

    <pre>
&lt;namer&gt;
    &lt;regExpOnName regExp="nws_precip_conus_(\d{4})(\d{2})(\d{2}).nc"
                  replaceString="NWS CONUS Precipitation for $2-$3-$1"/&gt;
&lt;/namer&gt;</pre>

  <p>the regular expression has 3 capturing groups</p>
  <ol>
    <li>The first capturing group, "(\d{4})", captures four digits, in this case the year.</li>
    <li>The second capturing group, "(\d{2})", captures two digits, in this case the month.</li>
    <li>The third capturing group, "(\d{2})", captures two digits, in this case the day of the month.</li>
  </ol>
  <p>When applied to the dataset name "nws_precip_conus_20130910.nc", the strings "2013", "09", and "10" are captured. After replacing the capturing group
    references in the <code>replaceString</code> attribute value, we get the name "NWS CONUS Precipitation 2013-09-10".</p>

  <div id="expanded" class="exercise">
    <h3>Exercise: Naming the NAM 12km Dataset</h3>

    <p>Add a <code>namer</code> element to the nam_12km <code>datasetScan</code> element that extracts the date/time from the file name and uses the date/time in
      generating a new name (similar to above) from the value of the path attribute matches.</p>
  </div>
  <h3>Adding <code>timeCoverage</code> Elements</h3>

  <p>A datasetScan element may contain an <code>addTimeCoverage</code> element. The <code>addTimeCoverage</code> element indicates that a
    <code>timeCoverage</code> metadata element should be added to each dataset in the collection and describes how to determine the time coverage for each
    datasets in the collection.</p>

  <p>Currently, the <code>addTimeCoverage</code> element can only construct start/duration <code>timeCoverage</code> elements and uses
    the dataset name to determine the start time. As described in the <a href="#Naming_Datasets">"Naming Datasets" section</a> above, the addTimeCoverage
    element applies a <a href="http://www.regular-expressions.info/">regular expression</a> match to the dataset name. If the match succeeds, any regular
    expression <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg">capturing groups</a> are used in the start time replacement
    string to build the start time string. The values of the following attributes are used to determine the time coverage: </p>

  <ol>
    <li>Either the <code>datasetNameMatchPattern</code> or the <code>datasetPathMatchPattern</code> attribute gives a regular expression used to match on the
      dataset name or path, respectively. If a match is found, a <strong>timeCoverage</strong> element is added to the dataset. The match pattern should include
      <a href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html#cg">capturing groups</a> which allow the match to save substrings from the
      dataset name.
    </li>
    <li>The <code>startTimeSubstitutionPattern</code> attribute value has all capture group references ("$n") replaced by the corresponding substring that was
      captured during the match. Theresulting string is used as the start value of the resulting <code>timeCoverage</code> element.
    </li>
    <li>The <code>duration</code> attribute value is used as the duration value of the resulting <code>timeCoverage</code> element.</li>
  </ol>
  <p>For instance, adding</p>

<pre>
&lt;addTimeCoverage datasetNameMatchPattern="nws_precip_conus_(\d{4})(\d{2})(\d{2}).nc"
                 startTimeSubstitutionPattern="$1-$2-$3T00:00:00"
                 duration="24 hours" /&gt;
</pre>

  <p>to a <code>datasetScan</code> element and given a data file named</p>

  <pre>nws_precip_conus_20130910.nc</pre>

  <p>results in the following <code>timeCoverage</code> element:</p>

<pre>
&lt;timeCoverage&gt;
    &lt;start&gt;2013-09-10T00:00:00&lt;/start&gt;
    &lt;duration&gt;24 hours&lt;/duration&gt;
&lt;/timeCoverage&gt;
</pre>

  <div id="expanded" class="exercise">
    <h3>Exercise: Add timeCoverage to the GFS Dataset</h3>

    <p>Add an <code>addTimeCoverage</code> element to the GFS <code>datasetScan</code> element that extracts the date/time from the file name and uses the
      date/time to generate the <code>timeCoverage</code> element (similar to above). </p>
  </div>

  <h3>Adding a "Latest" Proxy Datasets</h3>

  <p>With a real-time archive, it is convenient to define a "proxy" dataset that always points to the most recent dataset in a collection. Other types of proxy
    datasets may be useful as well and the <code>addProxies</code> element provides a place for describing proxy datasets. Currently, only two
    <code>addProxies</code> child elements are defined. They are both "Latest" proxy elements. The <code>simpleLatest</code> element adds a proxy dataset which
    proxies the existing dataset whose name is lexigraphically greatest (which finds the latest dataset assuming a timestamp is part of the dataset name). The
    <code>latestComplete</code> element behaves similarly to <code>simpleLatest</code> except that the proxied dataset does not include any datasets that have
    been modified more recently than a given time limit, e.g., you could specify you want the most recent (lexigraphically) dataset that hasn't been modified
    for 60 minutes. Both the <code>simpleLatest</code> and <code>latestComplete</code> elements must point to an existing <code>service</code> element.

  <p>

  <p>To add a "Latest" dataset to our "nam" dataset, we could add:</p>

  <pre>&lt;service name="latest" serviceType="Resolver" base="" /&gt;<br></pre>

  <p>to our catalog and</p>

  <pre>&lt;addProxies&gt;<br>    &lt;latestComplete name="latestComplete.xml" top="true" serviceName="latest" lastModifiedLimit="60" /&gt;<br>&lt;/addProxies&gt;<br></pre>

  <p>to our "nam" <code>datasetScan</code> element. This would result in the following dataset being at the top of the "nam" collection of datasets:
  </p>

  <pre>&lt;dataset name="latestComplete.xml" serviceName="latest" urlPath="latestComplete.xml" /&gt;</pre>

  <p>The <code>latestComplete</code> element includes a <code>name</code> attribute which provides the name of the proxy dataset, the <code>serviceName</code>
    attribute that references the service used by the proxy dataset, the <code>top</code> attribute which indicates if the proxy dataset should appear at the
    top or bottom of the list of datasets in this collection, and the <code>lastModifiedLimit</code> which feeds into the algorithm which determines which
    dataset is being proxied.</p>

  <p>The <code>simpleLatest</code> element allows for the same attributes as the <code>latestComplete</code> element minus the <code>lastModifiedLimit</code>
    attribute. In this case, all the attributes have default values: the <code>name</code> attribute defaults to "latest.xml", the <code>top</code> attribute
    defaults to "true", and the <code>serviceName</code> attribute defaults to "latest".</p>

</div>
<!-- end section -->

</body>
</html>
