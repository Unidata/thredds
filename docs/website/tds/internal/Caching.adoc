TDS Caching
===========

= TDS Caching

May, 2011

== Catalog caching test

mlode:8081, standard catalogs

=== 1. turn off catalog caching.

TdsMonitor: catalog service 18974 requests, 176 msecs/req, 794 Mbytes
total

294.8 Mbyte heap

Heap use:

1.  FileCache: 68 Mbytes, 208 files
1.  NetcdfDatasets : between 7.8M and 200K (Grib)
2.  Jsp : 16 M
3.  DataRootHandler / PathMatcher: 16 M
1.  159 entries, InvDatsetScan (20K each), InvDatsetImpl (1.4M !) but
most may be a shared InvCatalogFactory. But why do we have these? Are
they really FMRC ?
2.  _*remove InvCatalogFactory reference from InvCatalog - done for TDS
4.2.8*_
3.  InvDatasestScan is retaining link to its parents
4.  ehcache: 12 M
5.  fmrcDatasets : 6 M each. most in FmrcInvLite, 46M total
6.  quartz : 5 M
7.  bdb : 80 M
1.  bdb stores n 10M files, n us around 9 or 10. so we dont need 80 M
cache (!) at least right now
2.  bdb uses percent * JXV max bytes, default appears to be 2 % = 80 Mb.
3.  *Allow cache size to be set by user*
4.  Set to maxSize = 20 Mb for motherload (?)
5.  nCacheMiss=17,403
8.  org.geotoolkit 7M

=== 2. turn on catalog caching.

TdsMonitor: catalog service 10134 requests, 114 msecs/req 359 Mbytes

 

'''''

_below this line: update: Aug 10, 2006_

== Disk Caching

Settings on motherlode 3.12:

[width="100%",cols="20%,20%,20%,20%,20%",]
|=======================================================================
a|
*NetcdfFile, Nexrad2* (compress)

*GribIOSP, BufrIOSP* (index)

*WCS* (temp file)

 |CachePath |/data/tmp/thredds/cache/ |*DiskCache* a|
scour hourly

allow 1 Gbyte

|*Aggregation* (joinExisting) |CacheAged |/data/tmp/thredds/cacheAged/
|*DiskCache2* a|
scour 12 hours

over 10 days old

|*NetcdfServlet* (temp file) |NetcdfServletCachePath
|/data/tmp/thredds/ncCache/ |*DiskCache2* a|
scour daily

over 1 day old

|*CoordSysValidatorServlet* (upload file) |CdmValidatorCachePath
|/data/tmp/thredds/cdmCache/ |*DiskCache2* a|
scour daily

over 30 days

|=======================================================================

 

=== DiskCache

This disk-based cache is used when you need to write into a directory,
but you dont have write permission, for example:

1.  writing grib index files
2.  uncompressing radar level 2 files

The following directory is used for caching:
*$\{tomcat_home}/content/thredds/cache/,* unless overridden in
__*contentPath+``/params.xml''*__:

-----------------------------------------------------------------------------------------
    String cache = ServletParams.getInitParameter("CachePath", contentPath + "cache/");
    DiskCache.setRootDirectory(cache);
    DiskCache.setCachePolicy(false); // allow to write into data directory if possible

   // each hour, starting in 30 minutes
   timer.scheduleAtFixedRate( new CacheScourTask(), c.getTime(), (long) 1000 * 60 * 60 );
-----------------------------------------------------------------------------------------

The files are written in the data directory if possible, so that they
have the same lifetime as the data file. When that is not possible, the
files are written to **/content/thredds/cache**. This directory is
scoured (by a Timer in ThreddsDefault) every hour, to remove oldest
files when disk capacity is exceeded.

=== DiskCache2

This disk-based cache is used by **ucar.nc2.ncml.Aggregation**, to
persist NcML files, to make aggregation as efficient as possible.

The following directory is used for caching:
*$\{tomcat_home}/content/thredds/cachePersist/*

The following controls are set in ThreddsDefault.java. These need to be
externalized:

--------------------------------------------------------------------------------------------
    // for efficiency, persist aggregations. every 12 hours, delete stuff older than 10 days
    String cache2 = ServletParams.getInitParameter("CacheAged", contentPath + "cacheAged/");
--------------------------------------------------------------------------------------------

The directory is scoured (by a Timer in DiskCache2) removing files that
are older than a certain date.

'''''

== Object Caching

=== NetcdfFileCache

NetcdfFile objects are cached in memory for performance. When acquired,
the object is locked so another thread cannot use. When closed, the lock
is removed. When the cache is full, older objects are removed from the
cache, and all resources released.

The raf object is left open while its in the cache. This creates a read
lock which may prevent the file from being opened in write mode.
However. multiple readers can access.???

The following controls are set in ThreddsDefault.java. These need to be
externalized:

----------------------------------------------------------
    // allow 100 - 200 open files, cleanup every 2 minutes
    NetcdfFileCache.init(100, 200, 2 * 60, 2 * 60);
----------------------------------------------------------

=== NetcdfDatasetCache

NetcdfDataset objects are cached in memory for performance. This is used
by WCS server. The following controls are set in ThreddsDefault.java.
These need to be externalized:

----------------------------------------------------------
    // allow 100 - 200 open files, cleanup every 2 minutes
    NetcdfDataset.init(100, 200, 2 * 60, 2 * 60);
----------------------------------------------------------

=== FileCache

RandomAccessFile objects are cached in memory for performance. This is
used by the HTTP file server, in particular to support byte range
requests. The following controls are set in ThreddsDefault.java. These
need to be externalized:

----------------------------------------------------------
    // allow 100 - 200 open files, cleanup every 2 minutes
    FileCache.init(100, 200, 2 * 60, 2 * 60);
----------------------------------------------------------

'''''

== Catalog Caching

On startup, TDS reads in all static catalogs (which can be thought of as
configuration files) and caches them. If the catalog has an ``expires''
attribute, it will reread them upon expiration. You can force re-reading
by putting an old expires date on them. You can also force rereading the
catalogs through a ``reinit'' command, if you have https enabled and are
authorized.

Dynamic catalogs are generated dynamically. We are considering caching
them for some amount of time, but i dont think we’ve implemented yet. +

'''''

== File System Caching

May 2012

* Uses ehcache object caching
* Granularity is a directory
* Check lastModified date, if changed then make OS request for list of
directories
* Divide into daily (EG) subdirectories, so never have to scan older
ones.

=== motherlode memory use

* 44 CacheDirectory (avg 800 files/dir)
* 34,651 CacheFile (6.6M) (avg 190 bytes/file)
* 11,550 MFileCached (.xml and .gbx8 get filtered out) (462K) (avg 40
bytes/file, wraps the CacheFile)

currently have 1000 ehcache entity, clearly too large.

make each CacheDirectory seperate ehcache entity ??

possible turn off ehcache as default, not yet sure of benefits. possibly
not needed for just fmrc. most useful for datasetScan?

CDM default is dont use, must turn on by calling
DatasetCollectionManager.setController()

 

== FMRC Caching

* uses Berkeley DB
* default root dir is $\{user.home}/.unidata/bdb
* MetadataManager.setCacheDirectory(); +

=== motherlode memory use

* 44 FMRC (45M)
* 44 FmrcInvLite (33M)
* 469 FmrcInvLite.GridInventory (21M)
* 106 FmrcInvLite.GridSet (10M)
* 98K FmrcInvLite.TimeInv (4M)
* 44 NetcdfDataset (7M)
* 3K VariableDS (7M)
* 32K Attributes (4M)
