:source-highlighter: coderay
[[threddsDocs]]

= Upgrading to CDM / TDS version 5

== Requirements

* Java 8 is now required
* Tomcat 8 (servlet 3.1)
* On the command line when starting up Tomcat/TDS, you must specify *-Dtds.content.root.path=<content root>* where <content root> points to the top of the
content directory. Note that this is **$\{tomcat}/content/**, not **$\{tomcat}/content/thredds/**. Dont forget the trailing slash. For example:
+
-------------------------------------------------
-Dtds.content.root.path=/opt/tomcat-home/content/
-------------------------------------------------

== Overview

The configuration catalogs and internal state of the TDS has been extensively reworked to be able to scale to large numbers of catalogs, datasets, and
internal objects without excessive use of memory. A running TDS can be triggered to reread the configuration catalogs without having to restart. It
can be configured to reread only changed catalogs, for fast incremental updates. Other features have been added to make writing configuration catalogs
more maintainable, including the _catalogScan_ element, and default and standard services.

The other major enhancement is that _GridDataset_ is replaced by _FeatureDatasetCoverage_, to better support very large feature collections.
The Coverage API works with _coordinate values_ (not array indices), which solves various intractable problems that arise when using aray index
subsetting on large collections.

A number of API enhancements have been made to take advantage of evolution in the Java language, for example _try-with-resource_ and _foreach_ constructs.
The use of these make code simpler and more reliable.

Deprecated classes and methods have been removed, and the module structure and third-party jar use has been improved.

== API Changes

=== Unsigned Types

* *DataType* now has unsigned types: _UBYTE, USHORT, UINT, ULONG_
* *Array, ArrayScalar, ArrayByte, ArrayInt, ArrayShort, ArrayLong* factory and constructor methods now require _isUnsigned_ parameter.
* _Array.factory(class, shape) -> Array.factory(DataType, shape)_ or _Array.factory(dataType, class, shape)_
* _Array.get1DJavaArray(Class) -> Array.get1DJavaArray(DataType)_ or _Array.get1DJavaArray(Class, isUnsigned)_
* remove _Array.setUnsigned(), Variable.setUnsigned()_
* _Variable.getUnsigned() -> Variable.getDataType().getUnsigned()_
* _new Attribute(String name, List values) -> new Attribute(String name, List values, boolean isUnsigned)_
* _StructureDataScalar.addMember( String name, String desc, String units, DataType dtype, boolean isUnsigned, Number val ) -> StructureDataScalar.addMember( String name, String desc, String units, DataType dtype, Number val )_

=== Variable Length (vlen) Dimensions and Variables

* The CDM data model is clarified to allow *vlen* dimensions only in the outermost (fastest changing) Dimension.
* Reading a Variable with only a single vlen Dimension will result in a regular Array.
* Reading a Variable with a nested vlen Dimension will result in an ArrayObject containing regular Arrays of independent lengths.
* In both cases the returned array's DataType will be the primitive type.
* Previously the exact Array class and DataType returned from a read on a vlen was not well-defined.
* Use _Array.isVlen()_ to discover if an Array represents vlen data.
* _ArrayObject.factory(Class classType, Index index)_ is now _ArrayObject.factory(DataType dtype, Class classType, boolean isVlen, Index index)_
* Use _Array.makeVlenArray(int[] shape, Array[] data)_ to construct vlen data.
* see <<../netcdf-java/CDM/VariableLengthData#,here>>

=== AutoCloseable

*AutoCloseable* was introduced in Java 7, along with the _try-with-resources_ language feature. Use of this feature makes code more readable
and more reliable in ensuring that resources (like file handles) are released when done. We strongly recommend that you modify your code to take advantage of it
wherever possible, eg:

[source,java]
----
 try (NetcdfFile ncfile = NetcdfFile.open(location)) {
    ...
 } catch (IOException ioe) {
   // handle ioe here, or propagate by not using catch clause
 }
----

* The following now implement *AutoCloseable*, so can be the target of *_try-with-resource_* :
** *NetcdfFile, NetcdfFileWriter*
** *HTTPMethod, HTTPSession*
** *FeatureDataset*, *CoverageDataset*, *CoverageDatasetCollection*
** *CFPointWriter*, *Grib2NetcdfFile*
** *ArrayStructure* (deprecate _finish()_)
** *PointFeatureCollectionIterator* (deprecate _finish()_)
** *StructureDataIterator*, *PointFeatureIterator*, *PointFeatureCollectionIterator*, *NestedPointFeatureCollectionIterator*,
** *thredds.client.catalog.tools.DataFactory.Result*

=== Iterable

*Iterable* was introduced in Java 7, along with the _foreach_ language feature, and makes code more readable with less boilerplate, eg:

[source,java]
----
 for (StructureData sdata : myArrayStructure) {
    // ...
 }
----

* The following now implement *Iterable<>*, and so can be the target of *_foreach_* :
** *Range* implements _Iterable<Integer>_ (replace _first()_,_last()_,_stride()_,)
** *ArrayStructure* implements _Iterable<StructureData>_ (replace _getStructureDataIterator()_)
** *PointFeatureIterator* extends Iterator<PointFeature>_  (deprecate _finish()_)
*** in order for *PointFeatureIterator* to implement _Iterator<PointFeature>_, the _hasNext()_ and _next()_ methods cannot throw _IOException_.
The interface is changed to remove _throws IOException_, which will now be wrapped in _RuntimeException_.
** *PointFeatureCollection* implements _Iterable<PointFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *StationTimeSeriesFeatureCollection* implements _Iterable<StationTimeSeriesFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *ProfileFeatureCollection* implements _Iterable<ProfileFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *TrajectoryFeatureCollection* implements _Iterable<TrajectoryFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *StationProfileFeature* implements _Iterable<ProfileFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *StationProfileFeatureCollection* implements _Iterable<StationProfileFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *SectionFeature* implements _Iterable<ProfileFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)
** *SectionFeatureCollection* implements _Iterable<SectionFeature>_ (replace _hasNext()_, _next()_, _finish()_, _resetIteration()_)

=== ucar.nc2.util.DiskCache2

** all instances of *DiskCache2* now have one cleanup thread
** The _DiskCache2.exit()_ method is now static and need only be called once when the application is exiting.
** _DiskCache2.setLogger()_ is removed.
** _DiskCache2.cleanCache(File dir, StringBuffer sbuff, boolean isRoot)_ is now __DiskCache2.cleanCache(File dir, Formatter sbuff, boolean isRoot)__;
** deprecated methods are removed: _setCachePathPolicy(int cachePathPolicy, String cachePathPolicyParam) , setPolicy(int cachePathPolicy)_
** logging of routine cache cleanup is now at _DEBUG_ level

==== ucar.ma2.Range

** _Range.copy(String name)_ replaced by _Range.setName(String name)_
** _Range.getIterator()_ deprecated, use _Range.iterator()_
** Currently a Range is specified by _start:end:stride_
** In the future, may be extended with subclasses *RangeScatter* and *RangeComposite*
** You should use the iterator now to ensure correct functionality. To iterate over the values of the Range:

[source,java]
----
 for (int i=range.first(); i<=range.last(); i+= range.stride()) {    // REPLACE THIS
    // ...
 }

 for (int i : range) {  // USE THIS
   // ...
 }
----

=== ucar.nc2.util.cache

* *FileCache* and *FileFactory* take a `DatasetUrl` instead of a String location

=== ucar.nc2.dataset

In order to disambiguate remote protocols, all using _http:_, the utility method *DatasetUrl.findDatasetUrl(location)*
is used to determine the protocol and capture the result in a *DatasetUrl* object. Because this can be expensive, the
DatasetUrl should be calculated once and kept for the duration of the dataset access. When the protocol is already known, the
*DatasetUrl(ServiceType protocol, String location)* constructor may be used. The API is changed to allow/require the application
to compute these DatasetUrls.

* `NetcdfDataset.acquireDataset()` takes a DatasetUrl instead of a String location.
* the general method of `NetcdfDataset.openDataset()` takes a DatasetUrl instead of a String location.
Variants use a String location, and call `DatasetUrl.findDatasetUrl(location)`.

* `CoordinateAxis2D.getMidpoints()` was deprecated and now removed, use `getCoordValuesArray()`

=== ucar.nc2.ft.PointFeature

* Added method `getTimeUnit()`. An implementation exists in `ucar.nc2.ft.point.PointFeatureImpl`, so if your
`PointFeature` extends it, you shouldn't need to do any work.
* Removed method `getObservationTimeAsDate()`. Instead, use `getObservationTimeAsCalendarDate().toDate()`.
* Removed method `getNominalTimeAsDate()`. Instead, use `getNominalTimeAsCalendarDate().toDate()`.
* Removed method `getData()`. Instead, use `getDataAll()`.

=== ucar.ma2.MAMath

* Added method `equals(Array, Array)`. It is intended for use in `Object.equals()` implementations.
This means, among other things, that corresponding floating-point elements must be exactly equal, not merely within
some epsilon of each other.
* Added method `hashCode(Array array)`. It is intended for use in `Object.hashCode()` implementations and is
compatible with `equals(Array, Array)`.
* Renamed `isEqual(Array, Array)` to `fuzzyEquals(Array, Array)`. This was done to avoid (some) confusion with the new
`equals(Array, Array)`, and to highlight that this method performs *approximate* comparison of floating-point numbers,
instead of the exact comparison done by `equals(Array, Array)`.

=== Coordinate Systems

* *ucar.nc2.dataset.CoordTransBuilderIF* is split into *ucar.nc2.dataset.builder.HorizTransformBuilderIF* and *ucar.nc2.dataset.builder.VertTransformBuilderIF*
* *HorizTransformBuilderIF* now uses *AttributeContainer* instead of *NetcdfDataset, Variable*
* _CoordinateTransform.makeCoordinateTransform(NetcdfDataset ds, Variable ctv)_ is now _ProjectionCT makeCoordinateTransform(AttributeContainer ctv)_
* Previously, the optional _false_easting_, and _false_northing_ should match the units of the x and y projection coordinates
* in *ucar.nc2.dataset.CoordinateSystem*
** List<Dimension> getDomain() -> Collection<Dimension> getDomain()
** boolean isSubset(List<Dimension> subset, List<Dimension> set) -> isSubset(Collection<Dimension> subset, Collection<Dimension> set)

=== Feature Datasets

* *ucar.nc2.dt.TypedDatasetFactory* has been removed. Use *ucar.nc2.ft.FeatureDatasetFactoryManager*
* *ucar.nc2.dt.grid* is deprecated (but not removed) and is replaced by *ucar.nc2.ft2.coverage*
* *ucar.nc2.dt.point* and *ucar.nc2.dt.trajectory* have been removed, replaced by *ucar.nc2.ft.**
* In *FeatureDataset*, deprecated methods _getDateRange(), getStartDate(), getStartDate()_ have been removed
* In *FeatureDataset*, mutating method removed: _calcBounds()_

=== Point Feature Datasets (ucar.nc2.ft and ucar.nc2.ft.point)

* *FeatureCollection* has been renamed to *ucar.nc2.ft.DsgFeatureCollection* for clarity.
* *SectionFeature* and *SectionFeatureCollection* have been renamed to *TrajectoryProfileFeature* ,*TrajectoryProfileFeatureCollection* for clarity.
* *FeatureType.SECTION* renamed to *FeatureType.TRAJECTORY_PROFILE* for clarity.
* *NestedPointFeatureCollection* has been removed,  use *PointFeatureCC* and *PointFeatureCCC* instead when working with
    DsgFeatureCollection in a general way.
* In all the Point Feature classes, *DateUnit, Date*, and *DateRange* have been replaced by
    *CalendarDateUnit*, *CalendarDate*, and *CalendarDateRange* :
** In *PointFeature* and subclasses, deprecated methods _getObservationTimeAsDate(), getNominalTimeAsDate()_ have been removed
** In *ProfileFeature*, _getTime()_ returns _CalendarDate instead of Date
** In PointFeature implementations and subclasses, all constructors use *CalendarDateUnit* instead of *DateUnit*, and all
   _subset()_ and _flatten()_ methods use *CalendarDateRange* not *DateRange*
** In *CFPointWriter* subclasses, all constructors use *CalendarDateUnit* instead of *DateUnit*
* In *PointFeature*, deprecated method _getData()_ is removed; usually replace it with  _getDataAll()_
* In *PointFeatureCollection*, mutating methods are removed: _setCalendarDateRange(), setBoundingBox(), setSize(), calcBounds()_
* The time and altitude units for the collection can be found in the *DsgFeatureCollection*, and you can get the collection object
  from _PointFeature.getFeatureCollection()_
* In *PointFeatureIterator* and subclasses, methods _setCalculateBounds(), getDateRange(), getCalendarDateRange(), getBoundingBox(),
  getSize()_ have been removed. That information is obtained from the DsgFeatureCollection.
* In `PointFeatureIterator` and subclasses, `setBufferSize()` bas been removed.
* In `PointFeatureCollection` and subclasses, `getPointFeatureIterator()` no longer accepts a `bufferSize` argument.

=== Coverage Feature Datasets (ucar.nc2.ft2.coverage)

* Completely new package *ucar.nc2.ft2.coverage* that replaces *ucar.nc2.dt.grid*.
The class *FeatureDatasetCoverage* replaces *GridDataset*.
* Uses of classes in *ucar.nc2.dt.grid* are deprecated, though the code is still in the core jar file for now.
* For new API see <<../netcdf-java/reference/FeatureDatasets/CoverageFeatures#,CoverageFeatures>>
* *FeatureType.COVERAGE* is the general term for *GRID, FMRC, SWATH, CURVILINEAR* types.
Previously, GRID was used as the general type, now it referes to a specific type of Coverage.
Affects FeatureDatasetFactoryManager.open(FeatureType wantFeatureType, ...)

=== Shared Dimensions

* `Group.addDimension` and `Group.addDimensionIfNotExists` methods now throw an `IllegalArgumentException` if the
dimension isn't shared.
* `NetcdfFileWriter.addDimension` methods no longer have an `isShared` parameter. Such dimensions should always be
shared and allowing them to be private is confusing and error-prone.

=== Catalogs

* All uses of classes in *thredds.catalog* are deprecated. If you still need these, you must add *legacy.jar* to your path.
* TDS and CDM now use *thredds.server.catalog* and *thredds.client.catalog*
* *thredds.client.DatasetNode* now has _getDatasetsLogical()_ and _getDatasetsLocal()_ that does or does not dereference a CatalogRef.
You can also use _getDatasets()_ which uses a dereferenced catalog if it has already been read.

==== Catalog Schema changes

Schema version is now 1.2.

==== Client Catalogs

* *service* elements may not be nested inside of *dataset* elements, they must be directly contained in the *catalog* element.

==== Server Configuration Catalogs

* The *catalogScan* element is now available, which scans a directory for catalog files (any file ending in xml)
* The *datasetFmrc* element is no longer supported
* *datasetRoot* elements may not be contained inside of *service* elements, they must be directly contained in the *catalog* element
* *service* elements may not be nested inside of *dataset* elements, they must be directly contained in the *catalog* element.
* *service* elements no longer need to be explicitly defined in each config catalog, but may reference user defined global services
* If the *datatype/featureType* is defined for a dataset, then the *service* element may be ommited, and the default set of services for that *datatype* will be used.
* The *expires* attribute is no longer used.

==== Viewers

* *thredds.servlet.Viewer* has *InvDatasetImpl* changed to *Dataset*
* *thredds.servlet.ViewerLinkProvider* has *InvDatasetImpl* changed to *Dataset*
* *thredds.server.viewer.dataservice.ViewerService* has *InvDatasetImpl* changed to *Dataset*

==== DatasetScan

* *addID* is no longer needed, ids are always added
* *addDatasetSize* is no longer needed, the dataset size is always added
* With **addLatest**, the *service* name is no longer used, it is always __Resolver__, and the correct service is automatically added. Use *addLatest*
attribute for simple case.
* *fileSort:* by default, datasets at each collection level are listed in increasing order by filename. To change to decreasing order, use the
_<<reference/DatasetScan#filesSort,filesSort>>_ element.
* *sort:* deprecated in favor of *filesSort*
* *User pluggable classes implementing UserImplType* (crawlableDatasetImpl, crawlableDatasetFilterImpl, crawlableDatasetLabelerImpl,
crawlableDatasetSorterImpl) are no longer supported. (This was never officially released or documented).
* DatasetScan details are <<catalog/InvCatalogServerSpec#,here>>

==== Standard Services

* The TDS provides standard service elements, which know which services are appropriate for each Feature Type.
* User defined services in the root catalog are global and can be referenced by name in any other config catalog.
* User defined services in non-root catalogs are local to that catalog and override (by name) any global services.
* All services are enabled unless explicitly disabled
** Except for remote catalog services
* Standard service details are <<reference/Services#,here>>

==== FeatureCollections

* The *<<reference/collections/FeatureCollections#update,update>>* element default is now __startup="never"__, meaning do not update collection
on startup, and use existing indices when the collection is accessed.
* The *<<reference/collections/FeatureCollections#filesSort,fileSort>>* element is now inside the *featureCollection* itself, so it can be
processed uniformly for all types of feature collections. When a collection shows a list of files, the files will be sorted by increasing name. To use
a decreasing sort, use the element *<filesSort increasing="false" />* inside the *featureCollection* element. This supercedes the old way of placing
that element in the *<gribConfig>* element, or the older verbose *lexigraphicByName* element:
+
[source,xml]
-----------------------------------------------------------
  <filesSort>
    <lexigraphicByName increasing="false" />  // deprecated
  </filesSort>
-----------------------------------------------------------
* Feature Collection details are <<reference/collections/FeatureCollections#,here>>

==== Recommendations for 5.0 catalogs

* Put all *datasetRoot* elements in root catalog.
* Put all *catalogScan* elements in root catalog.
* Use StandardServices when possible. Annotate your datasets with *featureType* / **dataType**.
* Put all user-defined *service* elements in root catalog.
* Only use user-defined *service* elements in non-root catalogs when they are experimental or truly a special case.

=== Netcdf Subset Service (NCSS)

NCSS queries and responses have been improved and clarified. Generally the previous queries are backwards compatible. See
<<reference/services/NetcdfSubsetServiceReference#,NCSS Reference>> for details.

* New functionality:
. 2D time can now be handled for gridded datasets, with addition of _runtime_ and _timeOffset_ parameters.
. Handling of interval coordinates has been clarified.
. Use _ensCoord_ to select an ensemble member.

* Minor syntax changes:
. Use _time=all_ instead of _temporal=all_
. For station datasets, _subset=stns_ or _subset=bb_ is not needed. Just define _stns_ or a bounding box.


=== CdmrFeature Service

A new TDS service has been added for remote access to CDM Feature Datasets.

* Initial implementation for Coverage (Grid, FMRC, Swath) datasets, based on the new Coverage implementation in **ucar.nc2.ft2.coverage**.
* Target is a python client that has full access to all of the coordinate information and coordinate based subsetting capabilities of the Java client.
* Compatible / integrated with the Netcdf Subset Service (NCSS), using the same web API.

=== ThreddsConfig.xml

* You no longer turn catalog caching on or off, but you can control how many catalogs are cached (see
<<reference/ThreddsConfigXMLFile#CatalogCaching,here>> for the new syntax). So the following is no longer used:

[source,xml]
----------------------
<Catalog>
  <cache>false</cache>
</Catalog>
----------------------
* By default, most services are enabled, but may still be turned off in threddsConfig.xml.

== Recommendations for ESGF

You must determine the number of datasets that are contained in all of your catalogs. To get a report, enable
<<reference/RemoteManagement#,Remote Management>>, and from **https://server/thredds/admin/debug**, select __"Make Catalog Report"__. This may
take 5-20 minutes, depending on the numbers of catalogs.

Add the <<reference/ThreddsConfigXMLFile#CatalogCaching,ConfigCatalog>> element to threddsConfig.xml:

[source,xml]
--------------------------------------------------------
<ConfigCatalog>
  <keepInMemory>100</keepInMemory>
  <reread>check</reread>
  <dir>/tomcat_home/content/thredds/cache/catalog/</dir>
  <maxDatasets>1000000</maxDatasets>
</ConfigCatalog>
--------------------------------------------------------

where:

* *keepInMemory:* using the default value of 100 is probably good enough.
* *reread:* use value of _check_ to only read changed catalogs when restarting TDS.
* *dir* is where the catalog cache files are kept. Use the default directory (or symlink to another place) unless you have a good reason to change.
* **maxDatasets**: this is the number you found in step 1. Typical values for ESGF are 1 - 7 million. This is a maximum, so its ok to make it bigger
than you need.

Here are some additional, optional changes you can make to increase maintainability:

1.  Place all *datasetRoot* elements in the top catalog
2.  Place all *service* elements in the root catalog (__catalog.xml__). These can be referencced from any catalog.
3.  Remove *service* selements from non-root catalogs.
4.  Add a *<<catalog/InvCatalogServerSpec#catalogScan,catalogScan>>* element to the root catalog, replacing the list of catalogRefs listing all
the other catalogs.
* This assumes that other catalogs live in a subdirectory under the root, for example **$\{tds.content.root.path}/thredds/esgcet/**.

For example:

[source,xml]
----
<?xml version='1.0' encoding='UTF-8'?>
<catalog name="ESGF Master Catalog" version="1.2"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns="http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0"
      xsi:schemaLocation="http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0 http://www.unidata.ucar.edu/schemas/thredds/InvCatalog.1.2.xsd">

 <datasetRoot location="/esg/data" path="esg_testroot"/>
 <datasetRoot location="/esg/arc/data/" path="esg_obs4MIPs"/>
 <datasetRoot location="/esg/cordex/data/" path="esg_cordex"/>
 <datasetRoot location="/esg/specs/data/" path="esg_specs"/>

 <service base="/thredds/dodsC/" desc="OpenDAP" name="gridded" serviceType="OpenDAP">
  <property name="requires_authorization" value="false"/>
  <property name="application" value="Web Browser"/>
 </service>

 <service base="" name="fileservice" serviceType="Compound">
  <service base="/thredds/fileServer/" desc="HTTPServer" name="HTTPServer" serviceType="HTTPServer">
    <property name="requires_authorization" value="true"/>
    <property name="application" value="Web Browser"/>
    <property name="application" value="Web Script"/>
  </service>
  <service base="gsiftp://cmip-bdm1.badc.rl.ac.uk/" desc="GridFTP" name="GridFTPServer" serviceType="GridFTP">
    <property name="requires_authorization" value="true"/>
    <property name="application" value="DataMover-Lite"/>
  </service>
  <service base="/thredds/dodsC/" desc="OpenDAP" name="OpenDAPFiles" serviceType="OpenDAP">
    <property name="requires_authorization" value="false"/>
    <property name="application" value="Web Browser"/>
  </service>
 </service>

 <catalogScan name="ESGF catalogs" path="esgcet" location="esgcet" />

</catalog>
----
