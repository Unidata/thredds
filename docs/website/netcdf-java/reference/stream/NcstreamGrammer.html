<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <title>Ncstream Grammar</title>
  <link href="../../cdm.css" rel="stylesheet" type="text/css"/>

</head>

<body>
<h1>Ncstream Grammar</h1>

<h2>Version 2 (DRAFT)</h2>

<p>An <em><strong>ncstream</strong></em> is an ordered sequence of one or more messages:</p>
<pre>
   <strong>ncstream</strong> = <strong>MAGIC_START</strong>, <strong></strong>{message}, <strong>MAGIC_END</strong>
   <strong>message</strong> = headerMessage | dataMessage | errorMessage
   <strong>headerMessage</strong> = MAGIC_HEADER, vlenb, NcStreamProto.Header
   <strong>dataMessage</strong> = MAGIC_DATA, vlenb, NcStreamProto.Data, <strong>regData | vlenData | seqData</strong>
   <strong>errorMessage</strong> = MAGIC_ERR, vlenb, NcStreamProto.Error

   <strong>regData</strong> = vlenb, (byte)*vlenb
   <strong>vlenData</strong>= vlenn, {vlenb, (byte)*vlenb}*vlenn
   <strong>seqData</strong> = MAGIC_VDATA, {vlenb, NcStreamProto.StructureData}*, MAGIC_VEND
   <strong>seqData</strong> = {MAGIC_VDATA, vlenb, NcStreamProto.StructureData}*, MAGIC_VEND
   
   <strong>vlenb</strong> = variable length encoded positive integer == length of the following object in bytes
   <strong>vlenn</strong> = variable length encoded positive integer == number of objects that follow
   <strong>NcStreamProto.Header</strong> = Header message encoded by protobuf
   <strong>NcStreamProto.Data</strong> = Data message encoded by protobuf
   <strong>byte</strong> = actual bytes of data, encoding described by the NcStreamProto.Data message

primitives:

   <strong>MAGIC_START</strong> = 0x43, 0x44, 0x46, 0x53 
   <strong>MAGIC_HEADER</strong>= 0xad, 0xec, 0xce, 0xda 
   <strong>MAGIC_DATA</strong> =  0xab, 0xec, 0xce, 0xba <br/>   <strong>MAGIC_VDATA</strong> = 0xab, 0xef, 0xfe, 0xba <br/>
   <strong>MAGIC_VEND </strong> = 0xed, 0xef, 0xfe, 0xda <br/>
   <strong>MAGIC_ERR</strong>   = 0xab, 0xad, 0xba, 0xda 
   <strong>MAGIC_END</strong> =   0xed, 0xed, 0xde, 0xde</pre>
<p>The protobuf messages are defined by </p>
<ul>
  <li><strong>thredds\cdm\src\main\java\ucar\nc2\stream\ncStream.proto</strong></li>
  <li><strong>thredds\cdm\src\main\java\ucar\nc2\ft\point\remote\pointStream.proto</strong><br/>
  </li>
</ul>
<p>(these are files on Unidata's GitHub repository). These are compiled by the protobuf compiler into Java and C code that does the actual encoding/decoding
  from the stream. </p>

<p><strong>Rules</strong></p>
<ul>
  <li>Messages are ordered, and the resulting dataset may depend on the order.</li>
  <li>A shared dimension must be defined in the same or an earlier header message than a variable that uses it.</li>
  <li>A variable must be defined first in a header message before it can be used in a data message.</li>
  <li>A variable may have 0, 1, or many data messages. These are logically combined, with later data messages taking precedent. Missing data values are taken
    from the variable's <em>_FillValue</em> attribute if it exists, else the default missing value for the dataType, following netCDF conventions.
  </li>
</ul>
<h3>Data encoding</h3>

<p>There is just enough information in the stream to break the stream into messages and to know what kind of message it is. To interpret the data message
  correctly, one must have the definition of the variable. </p>
<pre>
message Data {<br/>  required string varName = 1; // full escaped name. change to hash or index to save space ??<br/>  required DataType dataType = 2;<br/>  optional Section section = 3; // not required for Sequence<br/>  optional bool bigend = 4 [default = true];<br/>  optional uint32 version = 5 [default = 0];<br/>  optional Compress compress = 6 [default = NONE];<br/>  optional fixed32 crc32 = 7;<br/>}</pre>
<ol>
  <li>full name of variable<em> (should this be index or hash in order to save space ?)</em></li>
  <li>data type</li>
  <li>section</li>
  <li>stored in big or small end. reader makes right.</li>
  <li>version</li>
  <li>compress (deflate)</li>
  <li>crc32 (not used yet)</li>
</ol>
<p><strong>Primitive types (byte, char, short, int, long, float, double)</strong>: arrays of primitives are stored in row-major order. The endian-ness is
  specified in the NcStreamProto.Data message when needed.</p>
<ul>
  <li><strong>char</strong> is a legacy data type contains uninterpreted characters, one character per byte. Typically these contain 7-bit ASCII characters.
  </li>
  <li><strong>byte, short, int, long</strong> may be interpreted as signed or unsigned. This is specified in the variable's header information.</li>
</ul>
<p><strong>Variable length types (String, Opaque): </strong>First the number of objects is written, then each object, preceded by its length in bytes as a
  vlen. Strings are encoded as UTF-8 bytes. Opaque is just a bag of bytes.</p>

<p><strong>Variable length arrays: </strong>First the number of objects is written, then each object, preceded by its length in bytes as a vlen. </p>

<p><strong>Structure types (Structure, Sequence): </strong>An array of StructureData. <em>Can be encoded in row or col (?).</em></p>

<h2>Data Encoding</h2>

<h3>Vlen data example</h3>
<blockquote>
  <pre>int levels(ninst= 23, acqtime=100, *);</pre>
</blockquote>
<p>encoded as</p>
<ol>
  <li>2300 as a vlen</li>
  <li>then 2300 objects, for each:
    <ol>
      <li>length in bytes</li>
      <li>nelems</li>
      <li>nelems integers</li>
    </ol>
  </li>
</ol>
<h3>&nbsp;</h3>

<h3>Compound Type</h3>

<p>Should be able to pop this in and out of a ByteBuffer (java) or void * (C), then use pointer manipulation to decode on the fly. Maybe good candidate for
  encodeing with protobuf</p>
<ol>
  <li>n</li>
  <li>n structs</li>
  <li>nheap</li>
  <li>nheap objects</li>
</ol>
<p>in this case, you have to read everything. if buffer has no vlens or strings, could use fixed size offsets. otherwise record the offsets. </p>
<ol>
  <li>n</li>
  <li>n structs
    <ol>
      <li>nheap</li>
      <li>nheap objects</li>
    </ol>
  </li>
</ol>
<p>(each struct contains its own heap)</p>
<ol>
  <li>n</li>
  <li>n lengths</li>
  <li>n structs
    <ol>
      <li>nheap</li>
      <li>nheap objects</li>
    </ol>
  </li>
</ol>
<p>(each struct contains its own heap)</p>

<p>this indicates maybe we should rewrite ArrayStructureBB to have seperate heaps for each struct.</p>

<h3>Nested Vlen</h3>

<p>A nested variable length field, goes on the heap</p>
<pre>netcdf Q:/cdmUnitTest/formats/netcdf4/vlen/cdm_sea_soundings.nc4 {
 dimensions:
   Sounding = 3;

 variables:
 
  Structure {
    int sounding_no;
    float temp_vl(*);
  } fun_soundings(Sounding=3);
}
</pre>
<h2>Notes and Questions</h2>

<p>Should have a way to efficiently encode sparse data. Look at Bigtable/hBase.</p>

<p>Should we store ints using vlen?</p>

<p>Forces on the design:</p>
<ul>
  <li>Allow data to be streamed.</li>
  <li>Allow compression</li>
  <li>Append only writing to disk</li>
  <li>Efficient encoding of variable length (ragged) arrays</li>
  <li>Efficient return of results from high level query.</li>
</ul>
<h2>Vlen Language</h2>

<p>We already have Fortran 90 syntax, and * indicating a variable length dimension. Do we really want to support arbitrary vlen dimension ??</p>
<ul>
  <li>array(outer, *)</li>
  <li>array(*, inner)</li>
  <li>array(outer, *, inner)</li>
</ul>
<p>An obvious thing to do is to use java/C &quot;array of arrays&quot;. rather than Fortran / netCDF rectangular arrays:</p>
<ul>
  <li>array[outer][*]</li>
  <li>array[*][inner]</li>
  <li>array[outer][*][inner]</li>
</ul>
<p>what does numPy do ??</p>

<p>java/C assumes in memory. Is this useful for very large, ie out of memory, data?</p>

<p>Nested Tables has taken approach that its better to use Structures rather than arrays, since there are usually multiple fields. Fortran programmers prefer
  arrays, but they are thinking of in memory.</p>

<p>What is the notation that allows a high level specification (eg SQL), that can be efficiently executed by a machine ?</p>

<p>Extending the array model to very large datasets may not be appropriate. Row vs column store.</p>

<p>What about a transform language on the netcdf4 / CDM data model, to allow efficient rewriting of data ? Then it also becomes an extraction language ??</p>

<p>&nbsp;</p>

<p>&nbsp;</p>
<hr width="100%"/>
<address>
  <img src="../../nc.gif" alt="" width="64" height="64"/> This document is maintained by <a href="mailto:caron@unidata.ucar.edu">John Caron</a> and was last
  updated July 2012
</address>
<p>&nbsp;</p>
</body>
</html>
